{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b721b6b3-bf94-4f8f-9aae-9fa119962b1d",
   "metadata": {},
   "source": [
    "# (WIP) PyTorch Cheatsheet\n",
    "\n",
    "Some of the most commonly used commands/setups in PyTorch.\n",
    "\n",
    "* TK - extra resources\n",
    "* TK - website with sources\n",
    "* TK - PyTorch best practices\n",
    "* TK - how to get help, one of the best ways to search \"pytorch how to make a convolutional neural network\" or \"pytorch transformer layers\" or \"pytorch loss functions\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98547c7d-2082-48db-a4ef-3d2b5091f22f",
   "metadata": {},
   "source": [
    "# Topics to cover\n",
    "\n",
    "* Imports\n",
    "    * Domain libraries\n",
    "    * Vision\n",
    "    * Text\n",
    "    * Audio \n",
    "* Device-agnostic code (CPU, GPU, MPS)\n",
    "* Basics\n",
    "    * Seeds\n",
    "* Neural networks\n",
    "    * Activation functions \n",
    "    * Transformers\n",
    "    * CNN's\n",
    "    * RNN's\n",
    "* Training loop\n",
    "* Testing loop\n",
    "* Optimizers\n",
    "* Loss functions\n",
    "* Evaluation\n",
    "\n",
    "* Extras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9c36f-3fd9-42b8-a5b6-a5a4de1e5cdd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98cf25ad-8e15-4692-a496-dc69b83a2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check the version\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e369e44-8cea-4171-87f4-93bf421155c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "# Can also import the common abbreviation \"nn\" for \"Neural Networks\"\n",
    "from torch import nn\n",
    "\n",
    "# Almost everything in PyTorch is called a \"Module\" (you build neural networks by stacking together Modules)\n",
    "this_is_a_module = nn.Linear(in_features=1,\n",
    "                             out_features=1)\n",
    "print(type(this_is_a_module))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b206a-6869-4d33-b313-e952aef82adf",
   "metadata": {},
   "source": [
    "### Data imports\n",
    "\n",
    "Since most of machine learning is finding patterns in data, it's good to know how to work with datasets in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6cf16f-f713-4a5a-8666-a622695eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch Dataset (you can store your data here) and DataLoader (you can load your data here)\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51efe1-609a-40c0-94a2-1f6c816599ef",
   "metadata": {},
   "source": [
    "## Domain libraries\n",
    "\n",
    "Depending on the specific problem you're working on, PyTorch has several domain libraries.\n",
    "\n",
    "- **[TorchVision](https://pytorch.org/vision/stable/index.html)** — PyTorch’s resident computer vision library. \n",
    "- **[TorchText](https://pytorch.org/text/stable/index.html)** — PyTorch’s in-built domain library for text.\n",
    "- [**TorchAudio**](https://pytorch.org/audio/stable/index.html) — PyTorch’s domain library for everything audio. \n",
    "- **[TorchRec](https://pytorch.org/torchrec/)** — PyTorch’s newest in-built domain library for powering recommendation engines with deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a5d29-d2f4-4089-b3a7-6b400f695d20",
   "metadata": {},
   "source": [
    "### Computer Vision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5353bfa2-d950-4f23-98c3-d29ff7c85e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base computer vision library\n",
    "import torchvision\n",
    "\n",
    "# Other components of TorchVision (premade datasets, pretrained models and image transforms)\n",
    "from torchvision import datasets, models, transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f35e-068f-4664-a16c-b3150a842ce2",
   "metadata": {},
   "source": [
    "### Text and Natural Language Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328b5026-fb0e-42f6-a50f-e4171a379c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base text and natural language processing library\n",
    "import torchtext\n",
    "\n",
    "# Other components of TorchText (premade datasets, pretrained models and text transforms)\n",
    "from torchtext import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409d640-a768-4423-a37c-3f4f2472b319",
   "metadata": {},
   "source": [
    "### Audio and Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956edd5a-291b-41d5-b7fa-507a171171dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base audio and speech processing library\n",
    "import torchaudio\n",
    "\n",
    "# Other components of TorchAudio (premade datasets, pretrained models and text transforms)\n",
    "from torchaudio import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf19cae-f18b-4bb9-af99-56725a739df7",
   "metadata": {},
   "source": [
    "### Recommendation systems\n",
    "\n",
    "**Note:** This library is currently in beta release, see the [GitHub page for installation](https://github.com/pytorch/torchrec#installation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb24f63-13c9-406c-9608-f66042a99f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base recommendation system library \n",
    "# import torchrec\n",
    "\n",
    "# # Other components of TorchRec\n",
    "# from torchrec import datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc7202-271a-4473-94fc-4945319bda37",
   "metadata": {},
   "source": [
    "## Device-agnostic code (using PyTorch on CPU, GPU or MPS)\n",
    "\n",
    "Much of deep learning involves computing on tensors. \n",
    "\n",
    "Computing on tensors generally happens much faster on GPUs (graphics processing units, typically from NVIDIA) than CPUs (computer processing units).\n",
    "\n",
    "MPS stands for \"Metal Performance Shader\" which is Apple's GPU (M1, M1 Pro, M2 etc).\n",
    "\n",
    "It is advised to perform training on the fastest piece of hardware you have available, which will generally be: NVIDIA GPU (`\"cuda\"`) > MPS device (`\"mps\"`) > CPU (`\"cpu\"`).\n",
    "\n",
    "* TK - See here for more: https://www.learnpytorch.io/00_pytorch_fundamentals/#2-getting-pytorch-to-run-on-the-gpu \n",
    "* MPS backend - https://pytorch.org/docs/stable/notes/mps.html \n",
    "* CUDA - https://pytorch.org/docs/stable/cuda.html \n",
    "\n",
    "**Note:** It is advised to setup device-agnostic code at the start of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081f561d-63f7-4609-86eb-868750eb8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device-agnostic code \n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps_is_available():\n",
    "    device = \"mps\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1f37-470f-486a-9a71-b7128ae295a9",
   "metadata": {},
   "source": [
    "### Sending a tensor to target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc6c29a-5d0a-45e1-9dde-547356e1366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.tensor([1, 2, 3]) \n",
    "print(x.device) # defaults to CPU \n",
    "\n",
    "# Send tensor to target device\n",
    "x = x.to(device)\n",
    "print(x.device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27d062-281b-4628-9374-c276640aceb8",
   "metadata": {},
   "source": [
    "## Setting random seeds\n",
    "\n",
    "A lot of machine learning and deep learning involves taking random numbers in tensors and then shaping those random numbers to find/represent patterns in real data. \n",
    "\n",
    "However, sometimes you'll want \"reproducible\" randomness.\n",
    "\n",
    "To do so, you can set the random seeds, see [Reproducibility (trying to take the random out of random)](https://www.learnpytorch.io/00_pytorch_fundamentals/#reproducibility-trying-to-take-the-random-out-of-random) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de557ce2-60df-4945-a57a-a8dc5e7de756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the random seed (you can set this to any number you like, it will \"flavour\"\n",
    "# the randomness with that number.\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(42) # set the seed again (try commenting this out and see what happens)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea594e-6ae6-4637-97bb-e52cd537df64",
   "metadata": {},
   "source": [
    "You can also set the random seed on the GPU (CUDA devices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2499098-9311-40b2-8ff3-63d433064aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed on GPU\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd5fba-9578-481b-850e-a968ade7700a",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "PyTorch has a very comprehensive library of pre-built neural network components (many of these are referred to as \"modules\" in the PyTorch ecosystem).\n",
    "\n",
    "At a fundamental level neural networks are stacks of *layers*. Each of these layers performs some kind of operation on an input and produces an output.\n",
    "\n",
    "How these layers stack together will dependent on the problem you're working on.\n",
    "\n",
    "It's one of the most active areas of research in machine learning: how to stack neural network layers together.\n",
    "\n",
    "The vast majority of neural network components in PyTorch are contained within the [`torch.nn` package](https://pytorch.org/docs/stable/nn.html) (`nn` is short for neural networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888b039b-c4ad-4f47-bad7-75ac8ca7db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497528d9-9fef-4323-8438-b7a298ed7ea3",
   "metadata": {},
   "source": [
    "### Linear layers\n",
    "\n",
    "TK - See more: https://pytorch.org/docs/stable/nn.html#linear-layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79047b27-3752-4e36-b7a9-a8e95bac20c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=10, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear layer with 10 in features and out features\n",
    "linear_layer = nn.Linear(in_features=10,\n",
    "                         out_features=10)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4972c605-39b4-43e4-aba4-02d9527cbbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_layer = nn.Identity()\n",
    "identity_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ee4f-67a1-4adb-92e1-7604ccbb4b62",
   "metadata": {},
   "source": [
    "### Convolutional layers (for making Convolutional Neural Networks)\n",
    "\n",
    "Naming of convolutional layers usually follows `torch.nn.ConvXd` where `X` can be a value of `1`, `2` or `3`.\n",
    "\n",
    "The `X` value represents the number of dimensions the convolution will operate over, for example, `1` for singular dimension text, `2` for two dimension images (height x width) and `3` for 3D objects such as video (video is considered a series of images with a time dimension, height x width x time).\n",
    "\n",
    "* TK - See more: https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "* TK - See more: https://www.learnpytorch.io/03_pytorch_computer_vision/#7-model-2-building-a-convolutional-neural-network-cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "882a8c21-cc87-4ebe-9a03-68f9765647c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 10, kernel_size=(3,), stride=(1,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Conv1d layer (often used for text with a singular dimension)\n",
    "conv1d = nn.Conv1d(in_channels=1,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)\n",
    "conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93d96033-75e4-4695-ad39-c488bb0a5038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Conv2d layer (often used for images with Height x Width dimensions)\n",
    "conv2d = nn.Conv2d(in_channels=3, # 3 channels for color images (red, green, blue)\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)\n",
    "conv2d                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b697f0-b80b-4dc7-a7d9-b771dad6c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(3, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Conv3d layer (often used for video with Height x Width x Time dimensions)\n",
    "conv3d = nn.Conv3d(in_channels=3,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)\n",
    "conv3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042dabb-9f18-4cd1-916b-b0d864048b7e",
   "metadata": {},
   "source": [
    "### TK - Transformer Layers\n",
    "\n",
    "See more: https://pytorch.org/docs/stable/nn.html#transformer-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6397f85-2263-47b1-b720-c3d46bf0eaef",
   "metadata": {},
   "source": [
    "### TK - RNN's\n",
    "\n",
    "See more: https://pytorch.org/docs/stable/nn.html#recurrent-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087611c-aae7-41fe-8397-03e01c885ade",
   "metadata": {},
   "source": [
    "### TK - Activation Functions \n",
    "\n",
    "See more: (non-linear) - https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38e1c3-1159-439d-ad3b-0db1b7fa3d12",
   "metadata": {},
   "source": [
    "### TK - Loss Functions\n",
    "\n",
    "* TK - Also called cost function, critertion\n",
    "\n",
    "See more: https://pytorch.org/docs/stable/nn.html#loss-functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5746cf2-2ff9-4621-a681-df36cac3beb1",
   "metadata": {},
   "source": [
    "### TK - Optimizers \n",
    "\n",
    "* TK - contained within the `torch.optim` package: https://pytorch.org/docs/stable/optim.html \n",
    "\n",
    "See more: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bef22-4a74-487e-b8c6-18cb90bb0964",
   "metadata": {},
   "source": [
    "## TK - End-to-end example workflow\n",
    "\n",
    "TK - see workflow notebook\n",
    "\n",
    "* create data\n",
    "* create neural network\n",
    "* create loss function/optimizer\n",
    "* create training loop\n",
    "* create testing loop\n",
    "* evaluate/plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc3833-e01b-40dc-a526-5647f314bd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
