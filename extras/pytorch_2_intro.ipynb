{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: A Quick PyTorch 2.0 Tutorial\n",
    "\n",
    "In short:\n",
    "\n",
    "If you have a new GPU (NVIDIA 40XX or A100, A10G etc), you can \"compile\" your models and often see speed ups.\n",
    "\n",
    "**Before PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "### Train model ###\n",
    "\n",
    "### Test model ###\n",
    "```\n",
    "\n",
    "**After PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "compiled_model = torch.compile(model) # <- new!\n",
    "\n",
    "### Train model ### <- faster!\n",
    "\n",
    "### Test model ### <- faster!\n",
    "```\n",
    "\n",
    "Things to note:\n",
    "* TK - add where it doesn't work\n",
    "\n",
    "## TK - Resources to learn more\n",
    "* PyTorch 2.0 launch blog post - https://pytorch.org/get-started/pytorch-2.0/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0.dev20230313 (should be 2.x+)\n",
      "[INFO] PyTorch 2.0 installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch 2.0 (currently from nightlies)\n",
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 (currently from nightlies)\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
    "    print(\"[INFO] PyTorch 2.0 installed, if you're on Google Colab, you may need to restart your runtime.\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.0 installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* add in info about PyTorch 2.0\n",
    "* a quick upgrade for speed ups\n",
    "* a quick note on which GPU will be needed (works best on NVIDIA GPUs, not macOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Check GPU\n",
    "\n",
    "* Best speedups are on newer NVIDIA GPUs (this is because PyTorch 2.0 leverages new NVIDIA hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU information:\n",
      "Wed Mar 15 06:31:17 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8    11W / 320W |   7023MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       993      G   /usr/lib/xorg/Xorg                 86MiB |\n",
      "|    0   N/A  N/A      1202      G   /usr/bin/gnome-shell               10MiB |\n",
      "|    0   N/A  N/A   1344104      C   ...de/pytorch/env/bin/python     6922MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU name: NVIDIA GeForce RTX 4080\n",
      "GPU capability score: (8, 9)\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  print(f'GPU name: {gpu_name}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  gpu_score = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {gpu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TK - add a table for NVIDIA GPUs and architectures etc and which lead to speedups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Simple training example \n",
    "\n",
    "* CIFAR10\n",
    "* ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0.dev20230313\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision version: 0.15.0.dev20230313\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25557032\n"
     ]
    }
   ],
   "source": [
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "transforms = model_weights.transforms()\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.crop_size = 32\n",
    "transforms.resize_size = 32 # Resize to 32x32, CIFAR10 is 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=32\n",
       "    resize_size=32\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "* Generally GPUs aren't the bottleneck of ML code\n",
    "* Data loading is the main bottleneck\n",
    "    * E.g. you want to get your data to the GPU as fast as possible = more workers (though in my experience this generally caps at about ~4 workers per GPU, though don't trust me, better to do your own experiments)\n",
    "* You want your GPUs to go brrrrr - https://horace.io/brrr_intro.html \n",
    "    * More here on crazy matmul improvements - https://twitter.com/cHHillee/status/1630274804795445248?s=20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 391 batches of size 128\n",
      "Test dataloader length: 79 batches of size 128\n",
      "Using number of workers: 16 (generally more workers means faster dataloading from CPU to GPU)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "import os\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Using number of workers: {NUM_WORKERS} (generally more workers means faster dataloading from CPU to GPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "def create_model():\n",
    "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "  # TK - adjust the output layer shape for CIFAR10\n",
    "  model.fc = torch.nn.Linear(2048, 10)\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea47f7e94b4b01b0ce9fb365c990d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae44643cea4298ac3ed679ebb8aa20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c3204ae94a4b24806518cdfb3b303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0508 | train_acc: 0.6511 | test_loss: 0.9077 | test_acc: 0.7124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e103cacea27443cbfbfd512da394ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935e8e7751004275b0c62589e2c3f380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.7122 | train_acc: 0.7649 | test_loss: 0.7965 | test_acc: 0.7312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4b922a976244578ed134a9d5b098bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c62f5376843e8ad629eeaf1cfd995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.7922 | train_acc: 0.7450 | test_loss: 0.7620 | test_acc: 0.7486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e395d0320c487cb1a2a4eb3ca03163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6240add4c5724066b0903f6f6d3a01cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.4927 | train_acc: 0.8334 | test_loss: 0.6233 | test_acc: 0.7911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36490a4a68d0432fbbca82faf79ddc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fe75c4d34c43e78b12af37431769d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3850 | train_acc: 0.8710 | test_loss: 0.5600 | test_acc: 0.8181\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.09265017509460449 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ce4a1297b040ae943a639eb157efeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac380b28131e47689651ef35f33d000c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/pytorch/env-nightly/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:93: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea988e6a4b44d11b688de0ad00870dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0581 | train_acc: 0.6461 | test_loss: 0.9207 | test_acc: 0.7037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93194ee8539b406abf90bf83e4a1ec4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce25e53f90194d92a05efb117c2d81a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.7607 | train_acc: 0.7491 | test_loss: 0.6929 | test_acc: 0.7607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091b822fa1f94c60881d83a77a89a31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0025eab6883468bb98eaa05cc8ff0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.5333 | train_acc: 0.8219 | test_loss: 0.6990 | test_acc: 0.7701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a88524883b4e94a8380501ac6a64cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22cb8d25d1b4aac8d13da69059ca577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.4452 | train_acc: 0.8500 | test_loss: 0.6522 | test_acc: 0.7868\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccb232d09134accad03325f36520fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6dd277d7b24c75908117b0e4757c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3782 | train_acc: 0.8726 | test_loss: 0.5966 | test_acc: 0.8137\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "compile_start_time = time.time()\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "compile_results = train(model=compiled_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graphs of results and compiled_results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "compile_results_df = pd.DataFrame(compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.050773</td>\n",
       "      <td>0.651091</td>\n",
       "      <td>0.907663</td>\n",
       "      <td>0.712421</td>\n",
       "      <td>9.281920</td>\n",
       "      <td>1.121336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712212</td>\n",
       "      <td>0.764866</td>\n",
       "      <td>0.796539</td>\n",
       "      <td>0.731210</td>\n",
       "      <td>8.354030</td>\n",
       "      <td>1.058375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792237</td>\n",
       "      <td>0.744953</td>\n",
       "      <td>0.761965</td>\n",
       "      <td>0.748616</td>\n",
       "      <td>8.290731</td>\n",
       "      <td>1.044391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492728</td>\n",
       "      <td>0.833416</td>\n",
       "      <td>0.623251</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>8.199355</td>\n",
       "      <td>1.064354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384985</td>\n",
       "      <td>0.870972</td>\n",
       "      <td>0.560035</td>\n",
       "      <td>0.818137</td>\n",
       "      <td>8.135148</td>\n",
       "      <td>1.067360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.050773   0.651091   0.907663  0.712421          9.281920   \n",
       "1    0.712212   0.764866   0.796539  0.731210          8.354030   \n",
       "2    0.792237   0.744953   0.761965  0.748616          8.290731   \n",
       "3    0.492728   0.833416   0.623251  0.791139          8.199355   \n",
       "4    0.384985   0.870972   0.560035  0.818137          8.135148   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         1.121336  \n",
       "1         1.058375  \n",
       "2         1.044391  \n",
       "3         1.064354  \n",
       "4         1.067360  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Make this more obvious that it's for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_train_epoch_time = results_df.train_epoch_time.mean()\n",
    "mean_test_epoch_time = results_df.test_epoch_time.mean()\n",
    "mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "mean_compile_train_epoch_time = compile_results_df.train_epoch_time.mean()\n",
    "mean_compile_test_epoch_time = compile_results_df.test_epoch_time.mean()\n",
    "mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "# Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "# Make both bars appear on the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "width = 0.3\n",
    "x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "plt.ylabel(\"Mean epoch time (seconds)\")\n",
    "# TK - make this title include dataset/model information for a better idea of what's happening\n",
    "plt.title(f\"Mean epoch time for non_compiled_results and compiled_results on {gpu_name}\")\n",
    "plt.legend();\n",
    "\n",
    "# mean_train_epoch_time, mean_compile_train_epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0711631298065185, 2.787031650543213)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_epoch_time, mean_compile_test_epoch_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Save results to file with GPU details\n",
    "\n",
    "TODO:\n",
    "* Save the results to file with GPU name and other details (run on multiple machines)\n",
    "* Run for multiple passes (e.g. 5x runs to average the time over each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv',\n",
       " 'single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create filename to save the results\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_name = \"ResNet50\"\n",
    "\n",
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_non_compiled_results, save_name_for_compiled_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Try for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    return results\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# TK - the first time you compile a model, the first few epochs will be slower than subsequent runs\n",
    "# TK - consider the first few epochs of training to be a \"warmup\" period\n",
    "def create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "    \n",
    "    compile_start_time = time.time()\n",
    "    ### New in PyTorch 2.x ###\n",
    "    compiled_model = torch.compile(model)\n",
    "    ##########################\n",
    "    compile_end_time = time.time()\n",
    "    compile_time = compile_end_time - compile_start_time\n",
    "    print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "    compile_results = train(model=compiled_model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=NUM_EPOCHS,\n",
    "                            device=device,\n",
    "                            disable_progress_bar=disable_progress_bar)\n",
    "    return compile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baa351ae6674098bac8b917e5636d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0919 | train_acc: 0.6337 | test_loss: 2.0762 | test_acc: 0.3386\n",
      "Epoch: 2 | train_loss: 0.9800 | train_acc: 0.6802 | test_loss: 0.9041 | test_acc: 0.7187\n",
      "Epoch: 3 | train_loss: 1.0408 | train_acc: 0.6728 | test_loss: 1.2705 | test_acc: 0.5824\n",
      "Epoch: 4 | train_loss: 1.1778 | train_acc: 0.6243 | test_loss: 0.9305 | test_acc: 0.6814\n",
      "Epoch: 5 | train_loss: 0.7107 | train_acc: 0.7608 | test_loss: 0.7061 | test_acc: 0.7624\n",
      "[INFO] Run 2 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.9880 | train_acc: 0.6734 | test_loss: 1.1726 | test_acc: 0.6754\n",
      "Epoch: 2 | train_loss: 0.7746 | train_acc: 0.7450 | test_loss: 1.5977 | test_acc: 0.5029\n",
      "Epoch: 3 | train_loss: 0.6560 | train_acc: 0.7796 | test_loss: 0.7231 | test_acc: 0.7686\n",
      "Epoch: 4 | train_loss: 0.4506 | train_acc: 0.8487 | test_loss: 0.6172 | test_acc: 0.7984\n",
      "Epoch: 5 | train_loss: 0.3917 | train_acc: 0.8698 | test_loss: 0.6530 | test_acc: 0.7902\n",
      "[INFO] Run 3 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0926 | train_acc: 0.6413 | test_loss: 0.9229 | test_acc: 0.6817\n",
      "Epoch: 2 | train_loss: 0.6747 | train_acc: 0.7765 | test_loss: 0.9285 | test_acc: 0.7038\n",
      "Epoch: 3 | train_loss: 0.5247 | train_acc: 0.8246 | test_loss: 0.7012 | test_acc: 0.7771\n",
      "Epoch: 4 | train_loss: 0.4624 | train_acc: 0.8468 | test_loss: 0.9575 | test_acc: 0.7041\n",
      "Epoch: 5 | train_loss: 0.9882 | train_acc: 0.6937 | test_loss: 0.7196 | test_acc: 0.7622\n",
      "[INFO] Run 4 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.2424 | train_acc: 0.6022 | test_loss: 1.0543 | test_acc: 0.6438\n",
      "Epoch: 2 | train_loss: 1.5711 | train_acc: 0.5013 | test_loss: 1.2990 | test_acc: 0.5683\n",
      "Epoch: 3 | train_loss: 1.1165 | train_acc: 0.6237 | test_loss: 1.1458 | test_acc: 0.6550\n",
      "Epoch: 4 | train_loss: 0.8633 | train_acc: 0.7078 | test_loss: 0.7992 | test_acc: 0.7223\n",
      "Epoch: 5 | train_loss: 0.6524 | train_acc: 0.7770 | test_loss: 0.7084 | test_acc: 0.7628\n",
      "[INFO] Run 5 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0162 | train_acc: 0.6609 | test_loss: 2.4731 | test_acc: 0.5943\n",
      "Epoch: 2 | train_loss: 1.0275 | train_acc: 0.6672 | test_loss: 0.9866 | test_acc: 0.6671\n",
      "Epoch: 3 | train_loss: 0.6845 | train_acc: 0.7695 | test_loss: 0.7045 | test_acc: 0.7590\n",
      "Epoch: 4 | train_loss: 0.5148 | train_acc: 0.8257 | test_loss: 0.6967 | test_acc: 0.7643\n",
      "Epoch: 5 | train_loss: 0.4161 | train_acc: 0.8608 | test_loss: 0.6180 | test_acc: 0.7918\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "num_runs = 5\n",
    "\n",
    "non_compile_results_multiple_runs = []\n",
    "for i in tqdm(range(num_runs)):\n",
    "    print(f\"[INFO] Run {i+1} of {num_runs} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.086228</td>\n",
       "      <td>0.642308</td>\n",
       "      <td>1.539821</td>\n",
       "      <td>0.586768</td>\n",
       "      <td>8.128362</td>\n",
       "      <td>1.153645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.005591</td>\n",
       "      <td>0.674043</td>\n",
       "      <td>1.143191</td>\n",
       "      <td>0.632160</td>\n",
       "      <td>8.125409</td>\n",
       "      <td>1.162120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804504</td>\n",
       "      <td>0.734044</td>\n",
       "      <td>0.909011</td>\n",
       "      <td>0.708406</td>\n",
       "      <td>8.143713</td>\n",
       "      <td>1.147044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693756</td>\n",
       "      <td>0.770664</td>\n",
       "      <td>0.800218</td>\n",
       "      <td>0.734098</td>\n",
       "      <td>8.207521</td>\n",
       "      <td>1.133451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.631825</td>\n",
       "      <td>0.792399</td>\n",
       "      <td>0.681031</td>\n",
       "      <td>0.773873</td>\n",
       "      <td>8.121648</td>\n",
       "      <td>1.130539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.086228   0.642308   1.539821  0.586768          8.128362   \n",
       "1    1.005591   0.674043   1.143191  0.632160          8.125409   \n",
       "2    0.804504   0.734044   0.909011  0.708406          8.143713   \n",
       "3    0.693756   0.770664   0.800218  0.734098          8.207521   \n",
       "4    0.631825   0.792399   0.681031  0.773873          8.121648   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         1.153645  \n",
       "1         1.162120  \n",
       "2         1.147044  \n",
       "3         1.133451  \n",
       "4         1.130539  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa28173ad5449d7b1c56a5d29bb69f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.001201629638671875 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n",
      "Epoch: 1 | train_loss: 1.0623 | train_acc: 0.6512 | test_loss: 4.3843 | test_acc: 0.5808 | train_epoch_time: 113.0886 | test_epoch_time: 9.5226\n",
      "Epoch: 2 | train_loss: 0.7229 | train_acc: 0.7597 | test_loss: 0.6516 | test_acc: 0.7846 | train_epoch_time: 8.8763 | test_epoch_time: 1.2360\n",
      "Epoch: 3 | train_loss: 0.5238 | train_acc: 0.8265 | test_loss: 0.6964 | test_acc: 0.7753 | train_epoch_time: 9.0969 | test_epoch_time: 1.2372\n",
      "Epoch: 4 | train_loss: 0.4316 | train_acc: 0.8562 | test_loss: 0.7876 | test_acc: 0.7681 | train_epoch_time: 9.1370 | test_epoch_time: 1.2442\n",
      "Epoch: 5 | train_loss: 0.3714 | train_acc: 0.8770 | test_loss: 0.6467 | test_acc: 0.7913 | train_epoch_time: 8.8687 | test_epoch_time: 1.2164\n",
      "Time to compile: 0.0013020038604736328 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n",
      "Epoch: 1 | train_loss: 1.0147 | train_acc: 0.6627 | test_loss: 1.0120 | test_acc: 0.6775 | train_epoch_time: 33.6930 | test_epoch_time: 9.7682\n",
      "Epoch: 2 | train_loss: 0.6658 | train_acc: 0.7793 | test_loss: 0.6458 | test_acc: 0.7845 | train_epoch_time: 9.2214 | test_epoch_time: 1.2594\n",
      "Epoch: 3 | train_loss: 0.5059 | train_acc: 0.8304 | test_loss: 0.6970 | test_acc: 0.7729 | train_epoch_time: 9.2780 | test_epoch_time: 1.2431\n",
      "Epoch: 4 | train_loss: 0.4229 | train_acc: 0.8577 | test_loss: 0.7064 | test_acc: 0.7794 | train_epoch_time: 8.8993 | test_epoch_time: 1.2440\n",
      "Epoch: 5 | train_loss: 0.3878 | train_acc: 0.8720 | test_loss: 2.2897 | test_acc: 0.6964 | train_epoch_time: 9.0321 | test_epoch_time: 1.2545\n",
      "Time to compile: 0.0012521743774414062 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n",
      "Epoch: 1 | train_loss: 1.0213 | train_acc: 0.6597 | test_loss: 0.7444 | test_acc: 0.7493 | train_epoch_time: 33.3863 | test_epoch_time: 9.7025\n",
      "Epoch: 2 | train_loss: 0.6505 | train_acc: 0.7838 | test_loss: 0.6918 | test_acc: 0.7733 | train_epoch_time: 8.9658 | test_epoch_time: 1.3632\n",
      "Epoch: 3 | train_loss: 0.7254 | train_acc: 0.7620 | test_loss: 0.8160 | test_acc: 0.7325 | train_epoch_time: 9.5846 | test_epoch_time: 1.2980\n",
      "Epoch: 4 | train_loss: 0.6710 | train_acc: 0.7797 | test_loss: 0.6754 | test_acc: 0.7742 | train_epoch_time: 9.4024 | test_epoch_time: 1.3002\n",
      "Epoch: 5 | train_loss: 0.4786 | train_acc: 0.8418 | test_loss: 14.1403 | test_acc: 0.4815 | train_epoch_time: 9.2344 | test_epoch_time: 1.2921\n",
      "Time to compile: 0.0012767314910888672 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n",
      "Epoch: 1 | train_loss: 1.1739 | train_acc: 0.6196 | test_loss: 0.7989 | test_acc: 0.7310 | train_epoch_time: 33.3643 | test_epoch_time: 10.2859\n",
      "Epoch: 2 | train_loss: 0.9519 | train_acc: 0.6945 | test_loss: 0.7895 | test_acc: 0.7297 | train_epoch_time: 9.0494 | test_epoch_time: 1.2903\n",
      "Epoch: 3 | train_loss: 0.6084 | train_acc: 0.7954 | test_loss: 0.6898 | test_acc: 0.7739 | train_epoch_time: 9.2013 | test_epoch_time: 1.3613\n",
      "Epoch: 4 | train_loss: 0.6756 | train_acc: 0.7782 | test_loss: 0.6916 | test_acc: 0.7674 | train_epoch_time: 8.9385 | test_epoch_time: 1.3266\n",
      "Epoch: 5 | train_loss: 0.4765 | train_acc: 0.8400 | test_loss: 0.6218 | test_acc: 0.7898 | train_epoch_time: 9.0536 | test_epoch_time: 1.3041\n",
      "Time to compile: 0.0012943744659423828 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n",
      "Epoch: 1 | train_loss: 1.1361 | train_acc: 0.6253 | test_loss: 1.0250 | test_acc: 0.6504 | train_epoch_time: 33.0945 | test_epoch_time: 10.5172\n",
      "Epoch: 2 | train_loss: 0.7331 | train_acc: 0.7538 | test_loss: 0.7200 | test_acc: 0.7584 | train_epoch_time: 9.4334 | test_epoch_time: 1.3253\n",
      "Epoch: 3 | train_loss: 0.5460 | train_acc: 0.8173 | test_loss: 0.6732 | test_acc: 0.7747 | train_epoch_time: 9.1096 | test_epoch_time: 1.3322\n",
      "Epoch: 4 | train_loss: 0.4480 | train_acc: 0.8482 | test_loss: 0.6301 | test_acc: 0.7966 | train_epoch_time: 9.2527 | test_epoch_time: 1.3375\n",
      "Epoch: 5 | train_loss: 0.3824 | train_acc: 0.8701 | test_loss: 0.5622 | test_acc: 0.8087 | train_epoch_time: 9.2290 | test_epoch_time: 1.3833\n"
     ]
    }
   ],
   "source": [
    "# Run compiled model for multiple runs\n",
    "num_runs = 5\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "\n",
    "compiled_results_multiple_runs = []\n",
    "for i in tqdm(range(num_runs)):\n",
    "    print(f\"[INFO] Run {i+1} of {num_runs} for compiled model\")\n",
    "    results = create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.081666</td>\n",
       "      <td>0.643673</td>\n",
       "      <td>1.592926</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>49.325343</td>\n",
       "      <td>9.959275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744834</td>\n",
       "      <td>0.754231</td>\n",
       "      <td>0.699740</td>\n",
       "      <td>0.766119</td>\n",
       "      <td>9.109263</td>\n",
       "      <td>1.294855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.581907</td>\n",
       "      <td>0.806328</td>\n",
       "      <td>0.714478</td>\n",
       "      <td>0.765882</td>\n",
       "      <td>9.254073</td>\n",
       "      <td>1.294373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529841</td>\n",
       "      <td>0.823989</td>\n",
       "      <td>0.698221</td>\n",
       "      <td>0.777136</td>\n",
       "      <td>9.125985</td>\n",
       "      <td>1.290488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419334</td>\n",
       "      <td>0.860186</td>\n",
       "      <td>3.652130</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>9.083553</td>\n",
       "      <td>1.290077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.081666   0.643673   1.592926  0.677809         49.325343   \n",
       "1    0.744834   0.754231   0.699740  0.766119          9.109263   \n",
       "2    0.581907   0.806328   0.714478  0.765882          9.254073   \n",
       "3    0.529841   0.823989   0.698221  0.777136          9.125985   \n",
       "4    0.419334   0.860186   3.652130  0.713548          9.083553   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         9.959275  \n",
       "1         1.294855  \n",
       "2         1.294373  \n",
       "3         1.290488  \n",
       "4         1.290077  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean()\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
