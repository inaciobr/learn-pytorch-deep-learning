{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: A Quick PyTorch 2.0 Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last updated: 2023-04-06 11:25:02.461525\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(f\"Notebook last updated: {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 30-second intro\n",
    "\n",
    "PyTorch 2.0 is out!\n",
    "\n",
    "With the main improvement being speed.\n",
    "\n",
    "This comes via a single backwards-compatible line.\n",
    "\n",
    "```python\n",
    "torch.compile()\n",
    "```\n",
    "\n",
    "In other words, after you create your model, you can pass it to `torch.compile()` and in turn expect speedups in training and inference on newer GPUs (e.g. NVIDIA RTX 40 series, A100, H100, the newer the GPU the more noticeable the speedups).\n",
    "\n",
    "> **Note:** Backwards-compatible means that if you already know PyTorch, such as via the [learnpytorch.io](https://learnpytorch.io) course, you can start using PyTorch 2.0 straight away."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick code examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50() # note: this could be any model\n",
    "\n",
    "### Train model ###\n",
    "\n",
    "### Test model ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50() # note: this could be any model\n",
    "compiled_model = torch.compile(model) # <- magic happens!\n",
    "\n",
    "### Train model ### <- faster!\n",
    "\n",
    "### Test model ### <- faster!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speedups\n",
    "\n",
    "Ok so the focus of PyTorch 2.0 is speed, how much faster is it actually?\n",
    "\n",
    "The PyTorch team ran tests across 163 open-source models from [Hugging Face Transformers](https://huggingface.co/docs/transformers/index), [timm](https://github.com/huggingface/pytorch-image-models) (PyTorch Image Models) and [TorchBench](https://github.com/pytorch/benchmark) (a curated set of popular code bases from across GitHub).\n",
    "\n",
    "This is important because unless PyTorch 2.0 is faster on models people actually use, it’s not faster.\n",
    "\n",
    "Using a mixture of AMP (automatic mixed precision or float16) training and float32 precision (higher precision requires more compute) the PyTorch team found that `torch.compile()` provides an average speedup of 43% in training on a NVIDIA A100 GPU.\n",
    "\n",
    "Or 38% on timm, 76% on TorchBench and 52% on Hugging Face Transformers.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/extras-pytorch-2-speedups.png\" alt=\"speedups for PyTorch 2.0 across various model resources\" width=650/>\n",
    "\n",
    "*PyTorch 2.0 speedups across various models from different locations. *Source:* [PyTorch 2.0 announcement post](https://pytorch.org/get-started/pytorch-2.0/).*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-minute overview\n",
    "\n",
    "> **Note:** The following is adapted from [*A Quick Introduction to PyTorch 2.0*](https://www.mrdbourke.com/pytorch-2/) on mrdbourke.com.\n",
    "\n",
    "What's happening behind the scenes of `torch.compile()`?\n",
    "\n",
    "`torch.compile()` is designed to \"just work\" but there are a few technologies behind it:\n",
    "* TorchDynamo\n",
    "* AOTAutograd\n",
    "* PrimTorch\n",
    "* TorchInductor\n",
    "\n",
    "The [PyTorch 2.0 getting started notes](https://pytorch.org/get-started/pytorch-2.0/) explain these in more detail but from a high level the two main improvements `torch.compile()` offers are:\n",
    "* Fusion (or operator fusion)\n",
    "* Graph capture (or graph tracing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion\n",
    "\n",
    "Fusion, also known as **operator fusion** is one of the best ways to make deep learning models go brrrrrr (brrrrrr is the sound your GPUs fan make when your models are training).\n",
    "\n",
    "Operator fusion condenses (like Dragon Ball Z) many operations into one (or many to less).\n",
    "\n",
    "Why?\n",
    "\n",
    "Modern GPUs have so much compute power they are often not compute limited, as in, the main bottleneck to training models is how fast can you get data from your CPU to your GPU.\n",
    "This is known as bandwidth or memory bandwidth.\n",
    "\n",
    "You want to reduce your bandwidth costs as much as possible.\n",
    "\n",
    "And feed the data hungry GPUs with as much data as possible.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/extras-memory-bandwidth-output-small.gif\" alt=\"example of memory bandwidth costs transferring data on and off the GPU\" width=950/>\n",
    "\n",
    "So instead of performing an operation on a piece of data and then saving the result to memory (increased bandwidth costs), you chain together as many operations as possible via fusion.\n",
    "\n",
    "A rough analogy would be using a blender to make a smoothie.\n",
    "\n",
    "Most blenders are good at blending things (like GPUs are good at performing matrix multiplications).\n",
    "\n",
    "Using a blender **without operator fusion** would be like adding each ingredient one by one and blending each time a new ingredient is added.\n",
    "Not only is this insane, it increases your bandwidth cost.\n",
    "\n",
    "The actual blending is fast each time (like GPU computations generally are) but you lose a bunch of time adding each ingredient one by one.\n",
    "\n",
    "Using a blender **with operator fusion** is akin to using a blender by adding all the ingredients at the start (operator fusion) and then performing the blend once.\n",
    "\n",
    "You lose a little time adding at the start but you gain all of the lost memory bandwidth time back."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph capture\n",
    "\n",
    "Graph capture I’m less confident explaining.\n",
    "\n",
    "But the way I think about is that graph capture or graph tracing is:\n",
    "\n",
    "* Going through a series of operations that need to happen, such as the operations in a neural network.\n",
    "* And capturing or tracing what needs to happen ahead of time.\n",
    "\n",
    "Computing **without graph capture** is like going to a new area and following GPS directions turn by turn.\n",
    "\n",
    "As a good human driver, you can follow the turns quite easily but you still have to think about each turn you take.\n",
    "\n",
    "This is the equivalent to PyTorch having to look up what each operation does as it does it.\n",
    "\n",
    "As in, to perform an addition, it has to look up what an addition does before it can perform it.\n",
    "\n",
    "It does this quickly but there’s still non-zero overhead.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/extras-graph-capture.gif\" alt=\"Graph capture\" width=\"950\"/>\n",
    "\n",
    "*Example of graph capture, mapping out the steps in a neural network and then capturing every operation that needs to happen ahead of time.*\n",
    "\n",
    "Computing **with graph capture** is like driving through your own neighbourhood.\n",
    "\n",
    "You barely think about what turns to make.\n",
    "\n",
    "Sometimes you get out of the car and realise you can’t remember the last 5 minutes of the drive.\n",
    "\n",
    "Your brain was functioning on autopilot, minimal overhead.\n",
    "\n",
    "However, it took you some time upfront to remember how to drive to your house.\n",
    "\n",
    "This is a caveat of graph capture, it takes a little time upfront to memorize the operations that need to happen but subsequent computations should be faster.\n",
    "\n",
    "Of course, this is a quick high-level overview of what’s happening behind the scenes of torch.compile()but it's how I understand it.\n",
    "\n",
    "For more on fusion and graph tracing, I’d recommend Horace He’s [*Making Deep Learning Go Brrrr From First Principles*](https://horace.io/brrr_intro.html) blog post."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to note\n",
    "\n",
    "Since PyTorch 2.0 was just released, there are a few limitations with some of the features.\n",
    "\n",
    "One of the main ones being with exporting models.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/extras-pytorch-2-limitations.png\" alt=\"PyTorch 2 limitations\" width=650/>\n",
    "\n",
    "*There are a few caveats when using the PyTorch 2.0 features, such as not being about to export to mobile devices when using the `torch.compile()` default options. However, there are work arounds to this and improved exporting is on the PyTorch 2.x roadmap. *Source:* [PyTorch 2.0 announcement post](https://pytorch.org/get-started/pytorch-2.0/).*\n",
    "\n",
    "However, these will likely be fixed in future releases.\n",
    "\n",
    "Another main limitation is that because the features of PyTorch 2.0 are designed for newer hardware, old GPUs and desktop-class GPUs (e.g. NVIDIA RTX 30 series) will likely see less speedups than newer hardware."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - What we're going to cover\n",
    "\n",
    "Since many of the upgrades in PyTorch 2.0 are under the hood, in this notebook we're going to run a compartive speed test.\n",
    "\n",
    "Namely we'll make two of the same models, one using the default PyTorch setup and the other using the new `torch.compile()` setup.\n",
    "\n",
    "1. Model 1 - no `torch.compile()`.\n",
    "2. Model 2 - `torch.compile()`.\n",
    "\n",
    "We'll then compare the training/testing times of both models for single run and multiple runs.\n",
    "\n",
    "TK - replace this table with the table below\n",
    "\n",
    "| **Experiment** | **Model 1** | **Model 2** | \n",
    "|----- |-----|-----|\n",
    "| Single run | no `torch.compile()` | with `torch.compile()` |\n",
    "| Multiple runs (3 x single runs) | no `torch.compile()` | with `torch.compile()` |\n",
    "\n",
    "To keep things straight forward, we'll use the same modelling and data setup for all experiments:\n",
    "\n",
    "| **Model** | **Data** | **Epochs** | **Batch size** | **Image size** |\n",
    "|----- |-----|-----|-----|-----|\n",
    "| [ResNet50](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.resnet50) (from TorchVision) | [CIFAR10](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html) (from TorchVision) | 5 (single run) | 128 | 224 |\n",
    "\n",
    "We've chosen ResNet50 here for ease of access or use, however, you could substitute any model you like.\n",
    "\n",
    "And the biggest speedups I've noticed are when the GPU computes on as much data as possible (e.g. larger batch size/image size/data size/model size). \n",
    "\n",
    "> **Note:** Depending on the size of your GPU, you may have to lower the batch size (or image size) to fit the model on your GPU. If you're using a GPU with 8GB of memory or less, you may have to lower the batch size to 64 or 32."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - 0. Getting setup\n",
    "\n",
    "To get setup we'll first check for PyTorch 2.x+ and install it if it's not available. \n",
    "\n",
    "You can see how to install PyTorch 2.x on your own system in the [documentation](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current PyTorch version: 2.0.0+cu118 (should be 2.x+)\n",
      "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 if necessary\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\")\n",
    "    import torch\n",
    "    pt_version = torch.__version__\n",
    "    print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful!\n",
    "\n",
    "Now PyTorch 2.x is installed, let's check out a new feature!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Get GPU info\n",
    "\n",
    "Time to get GPU info.\n",
    "\n",
    "It's important to know that many of the speedups PyTorch 2.0 offers are best experienced on newer GPUs.\n",
    "\n",
    "This is because PyTorch 2.0 takes advantage of the new hardware on newer GPUs.\n",
    "\n",
    "You can see a list of [NVIDIA GPU compute capability scores](https://developer.nvidia.com/cuda-gpus) on NVIDIA's developer page.\n",
    "\n",
    "Here are some scores of NVIDIA GPUs released in 2020 or later:\n",
    "\n",
    "| **NVIDIA GPU** | **Compute capability score** | **GPU Type** | **Release year** | **Architecture** |\n",
    "|----- |-----| -----| -----| -----| \n",
    "| RTX 4090 | 8.9 | Desktop-class | 2022 | [Ada Lovelace](https://www.nvidia.com/en-au/geforce/ada-lovelace-architecture/) |\n",
    "| RTX 4080 | 8.9 | Desktop-class | 2022 | Ada Lovelace |\n",
    "| RTX 4070 Ti | 8.9 | Desktop-class | 2022 | Ada Lovelace |\n",
    "| RTX 3090 | 8.6 | Desktop-class | 2020 | [Ampere](https://en.wikipedia.org/wiki/Ampere_(microarchitecture)) |\n",
    "| RTX 3080 | 8.6 | Desktop-class | 2020 | Ampere| \n",
    "| RTX 3070 | 8.6 | Desktop-class | 2020 | Ampere |  \n",
    "| RTX 3060 Ti | 8.6 | Desktop-class | 2020 | Ampere | \n",
    "| A100 | 8.0 | Datacenter-class | 2020 | Ampere |\n",
    "| A10 | 8.6 | Datacenter-class | 2021 | Ampere |\n",
    "| H100 | 9.0 | Datacenter-class | 2022 | [Hopper](https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/) | \n",
    "\n",
    "GPUs with a compute capability score of 8.0 or above are likely to see the biggest speedups.\n",
    "\n",
    "And GPUs which are datacenter-class (e.g. A100, A10, H100) are likely to see more significant speedups than desktop-class GPUs (e.g. RTX 3090, RTX 3080, RTX 3070, RTX 3060 Ti).\n",
    "\n",
    "We can check the compute capbility score of our GPU using [`torch.cuda.get_device_capability()`](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html).\n",
    "\n",
    "This will output a tuple of `(major, minor)` compute capability scores, for example, `(8, 0)` for the A100.\n",
    "\n",
    "We'll also get some other details about our GPU such as the name and other info using [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface).  \n",
    "\n",
    "> **Note:** If you're running on Google Colab, you'll need to setup a GPU: runtime -> change runtime type -> hardware accelerator. The best speedups are on newer NVIDIA/AMD GPUs (this is because PyTorch 2.0 leverages new GPU hardware). This tutorial focuses on NVIDIA GPUs.\n",
    "\n",
    "> **Resource:** For an in-depth comparison of many different NVIDIA GPUs and their speeds, costs and tradeoffs, I'd recommend reading Tim Dettmers' [*Which GPU for deep learning?*](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA_TITAN_RTX\n",
      "GPU capability score: (7, 5)\n",
      "GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\n",
      "GPU information:\n",
      "Thu Apr  6 12:14:08 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 59%   67C    P8    14W / 280W |  14646MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1020      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A   1415245      G   /usr/lib/xorg/Xorg                148MiB |\n",
      "|    0   N/A  N/A   1415374      G   /usr/bin/gnome-shell                7MiB |\n",
      "|    0   N/A  N/A   4144532      C   ...ch/env-nightly/bin/python    14412MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  GPU_NAME = gpu_name.replace(\" \", \"_\")\n",
    "  print(f'GPU name: {GPU_NAME}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  GPU_SCORE = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
    "  if GPU_SCORE > (8, 0):\n",
    "    print(f\"GPU score higher than (8, 0), PyTorch 2.x speedup features available.\")\n",
    "  else:\n",
    "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
    "  \n",
    "  # Print GPU info\n",
    "  print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "else:\n",
    "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - New feature: globally set devices\n",
    "\n",
    "One of my favourite new features in PyTorch 2.x is being able to set the [default device type](https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html ) via:\n",
    "* Context manager\n",
    "* Globally\n",
    "\n",
    "Previously, you could only set the default device type via:\n",
    "* `tensor.to(device)`\n",
    "\n",
    "Let's see these two new device settings in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: cuda:0\n",
      "Layer creating data on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the device with context manager (requires PyTorch 2.x+)\n",
    "with torch.device(device):\n",
    "    # All tensors created in this block will be on device\n",
    "    layer = torch.nn.Linear(20, 30)\n",
    "    print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "    print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how about setting the global device?\n",
    "\n",
    "This will mean that any tensors created without an explicit device will be created on the device you set by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: cuda:0\n",
      "Layer creating data on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the device globally\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# All tensors created will be on the global device by default\n",
    "layer = torch.nn.Linear(20, 30)\n",
    "print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now back to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: cpu\n",
      "Layer creating data on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# Set the device globally\n",
    "torch.set_default_device(\"cpu\")\n",
    "\n",
    "# All tensors created will be on \"cpu\"\n",
    "layer = torch.nn.Linear(20, 30)\n",
    "print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Simple training example \n",
    "\n",
    "Okay, time to measure speed!\n",
    "\n",
    "To keep things simple, we'll run a series of four experiments, all with:\n",
    "\n",
    "* **Model:** ResNet50 (from [TorchVision](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html))\n",
    "* **Data:** CIFAR10 (from [TorchVision](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html))\n",
    "* **Epochs:** 5 (single run) and 3x5 (multiple runs)\n",
    "* **Batch size:** 128\n",
    "* **Image size:** 224\n",
    "\n",
    "However, each experiment will be run with and without `torch.compile()`.\n",
    "\n",
    "In table form:\n",
    "\n",
    "| **Experiment** | **Model** | **Data** | **Epochs** | **Batch size** | **Image size** | **`torch.compile()`** |  \n",
    "|----- |-----| -----| -----| -----| -----| -----|\n",
    "| 1 (single run) | ResNet50 | CIFAR10 | 5 | 128 | 224 | No |\n",
    "| 2 (single run) | ResNet50 | CIFAR10 | 5 | 128 | 224 | Yes |\n",
    "| 3 (multi-run) | ResNet50 | CIFAR10 | 3x5 | 128 | 224 | No |\n",
    "| 4 (multi-run) | ResNet50 | CIFAR10 | 3x5 | 128 | 224 | Yes |\n",
    "\n",
    "Why the single and multiple runs?\n",
    "\n",
    "Because we can measure speedups via a single run, however, we'll also want to run the tests multiple times to get an average. \n",
    "\n",
    "> **Note:** Depending on the size of your GPU (the memory available), you may have to lower the batch size or the image size. This tutorial is focused on using an A100 GPU (with 40GB of memory) available on Google Colab Pro. \n",
    "\n",
    "Let's start by importing `torch` and `torchvision` and setting the target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "TorchVision version: 0.15.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")\n",
    "\n",
    "# Set the target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Create model and transforms\n",
    "\n",
    "Let's now create our model and transforms.\n",
    "\n",
    "We'll use the same setup to create the model and transforms we covered in [06. PyTorch Transfer Learning section 2.2](https://www.learnpytorch.io/06_pytorch_transfer_learning/).\n",
    "\n",
    "In essence, we'll create the model and transforms for the model using the `torchvision.models` API.\n",
    "\n",
    "We can get the weights and transforms for ResNet50 using the following:\n",
    "* `model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2` (this requires `torchvision` 0.14 or later).\n",
    "* `transforms = model_weights.transforms()` (once we have the weights, we can get the appropriate transforms for the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of model: 25557032\n",
      "Model transforms:\n",
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create model weights and transforms\n",
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2 # <- use the latest weights (could also use .DEFAULT)\n",
    "transforms = model_weights.transforms()\n",
    "\n",
    "# Setup model\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "# Count the number of parameters in the model \n",
    "total_params = sum(\n",
    "    param.numel() for param in model.parameters() # <- all params\n",
    "\t# param.numel() for param in model.parameters() if param.requires_grad # <- only trainable params\n",
    ")\n",
    "\n",
    "print(f\"Total parameters of model: {total_params}\")\n",
    "print(f\"Model transforms:\\n{transforms}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn the above code into a function so we can replicate it later, we'll also adjust the last layer's (`model.fc`) output features to match the number of classes in CIFAR10 (10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=10):\n",
    "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "  \n",
    "  # Adjust the number of output features in model to match the number of classes in the dataset\n",
    "  model.fc = torch.nn.Linear(in_features=2048, \n",
    "                             out_features=num_classes)\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Speedups are most noticeable when a large portion of the GPU is being used\n",
    "\n",
    "Since modern GPUs are so fast at performing operations, you will often notice the majority of speedups when as much data as possible is on the GPU.\n",
    "\n",
    "This can be achieved by:\n",
    "* **Increasing the batch size** - More samples per batch means more samples on the GPU, for example, using a batch size of 256 instead of 32.\n",
    "* **Increasing data size** - For example, using larger image size, 224x224 instead of 32x32. A larger data size means that more tensor operations will be happening on the GPU.\n",
    "* **Increasing model size** - For example, using a larger model such as ResNet101 instead of ResNet50. A larger model means that more tensor operations will be happening on the GPU.\n",
    "* **Decreasing data transfer** - For example, setting up all your tensors to be on GPU memory, this minizes the amount of data transfer between the CPU and GPU.\n",
    "\n",
    "All of these result in *more* data being on the GPU.\n",
    "\n",
    "You may be thinking, \"but doesn't this mean that the GPU will be slower because it has to do more work?\"\n",
    "\n",
    "This is correct, operations may take longer when using *more* data on the GPU, however, they benefit from [parallelism](https://en.wikipedia.org/wiki/Parallel_computing) (many operations happening at once).\n",
    "\n",
    "This means that although *more* operations are happening, the GPU is performing as many of them as possible simultaneously.\n",
    "\n",
    "So while you may see speedups with smaller datasets, models, batch sizes and data sizes, however, you will tend to see the *biggest* speedups with increasing scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Checking the memory limits of our GPU\n",
    "\n",
    "To take advantage of speedups at scale, let's check how much memory our GPU has.\n",
    "\n",
    "If your GPU has less memory, you may need to decrease the batch size or image size (less potential for speedups).\n",
    "\n",
    "We can check the memory available on our GPU using [`torch.cuda.mem_get_info()`](https://pytorch.org/docs/stable/generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info).\n",
    "\n",
    "This will return a tuple of `(total_free_gpu_memory, total_gpu_memory)`.\n",
    "\n",
    "Where:\n",
    "* `total_free_gpu_memory` is the amount of memory currently *not being used* on the GPU in bytes.\n",
    "* `total_gpu_memory` is the total amount of memory available on the GPU in bytes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total free GPU memory: 24.214 GB\n",
      "Total GPU memory: 25.386 GB\n"
     ]
    }
   ],
   "source": [
    "# Check available GPU memory and total GPU memory \n",
    "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
    "print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\")\n",
    "print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)} GB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful!\n",
    "\n",
    "The takeaways here are:\n",
    "1. The higher the memory available on your GPU, **the bigger your batch size can be, the bigger your model can be, the bigger your data samples can be**. \n",
    "2. For speedups, you should always be trying to use **as much of the GPU as possible**.\n",
    "\n",
    "Let's write some code to use a larger batch size if more GPU memory is available.\n",
    "\n",
    "> **Note:** The ideal batch size you use will depend on the specific GPU and dataset and model you're working with. The code below is specifically targeted for the A100 GPU available on Google Colab Pro. However, you may to adjust it for your own GPU. As if you set the batch size too high, you may run into CUDA out of memory errors.\n",
    "\n",
    "If the total memory on the GPU available is **above 16GB**, let's use a batch size of 128 and an image size of 224 (both of these values can be increased on GPUs with more memory).\n",
    "\n",
    "If the total memory on the GPU available is **below 16GB**, let's use a batch size of 32 and an image size of 64 (both of these values can be altered on GPUs with less memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory available is 24.214 GB, using batch size of 128 and image size 224\n"
     ]
    }
   ],
   "source": [
    "# Set batch size depending on amount of GPU memory\n",
    "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
    "if total_free_gpu_memory_gb >= 16:\n",
    "  BATCH_SIZE = 128\n",
    "  IMAGE_SIZE = 224\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "else:\n",
    "  BATCH_SIZE = 32\n",
    "  IMAGE_SIZE = 128\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's adjust the `transforms` to use the respective `IMAGE_SIZE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data transforms:\n",
      "ImageClassification(\n",
      "    crop_size=224\n",
      "    resize_size=224\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transforms.crop_size = IMAGE_SIZE\n",
    "transforms.resize_size = IMAGE_SIZE \n",
    "print(f\"Updated data transforms:\\n{transforms}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - More potential speedups with TF32\n",
    "\n",
    "TF32 stands for TensorFloat-32, a data format which is a combination of 16-bit and 32-bit floating point numbers.\n",
    "\n",
    "You can read more about how it works on [NVIDIA's blog](https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/).\n",
    "\n",
    "The main thing you should know is that it allows you to **perform faster matrix multiplications** on GPUs with the Ampere architecture and above (a compute capability score of 8.0+).\n",
    "\n",
    "Although it's not specific to PyTorch 2.0, since we're talking about newer GPUs, it's worth mentioning.\n",
    "\n",
    "If you're using a GPU with a compute capability score of 8.0 or above, you can enable TF32 by setting [`torch.backends.cuda.matmul.allow_tf32 = True`](https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices) (this defaults to `False`).\n",
    "\n",
    "Let's write a check that sets it automatically for us based on our GPUs compute capability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU with score: (7, 5), TensorFloat32 (TF32) not available, to use it you need a GPU with score >= (8, 0)\n"
     ]
    }
   ],
   "source": [
    "if GPU_SCORE >= (8, 0):\n",
    "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFloat32 (TF32) computing (faster on new GPUs)\")\n",
    "  torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 (TF32) not available, to use it you need a GPU with score >= (8, 0)\")\n",
    "  torch.backends.cuda.matmul.allow_tf32 = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Make datasets\n",
    "\n",
    "Computing setup done!\n",
    "\n",
    "Let's now create our datasets.\n",
    "\n",
    "To keep things simple, we'll use [CIFAR10](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html) since it's readily available in `torchvision`.\n",
    "\n",
    "Some info about CIFAR10 the [CIFAR10 website](https://www.cs.toronto.edu/~kriz/cifar.html):\n",
    "\n",
    "* CIFAR10 is a dataset of 60,000 32x32 color images in 10 classes, with 6,000 images per class.\n",
    "* There are 50,000 training images and 10,000 test images.\n",
    "* The dataset contains 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "\n",
    "Although the original dataset consists of 32x32 images, we'll use the `transforms` we created earlier to resize them to 224x224 (larger images provide more information and will take up more memory on the GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='.', \n",
    "                                             train=True, \n",
    "                                             download=True, \n",
    "                                             transform=transforms)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', \n",
    "                                            train=False, # want the test split\n",
    "                                            download=True, \n",
    "                                            transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Create DataLoaders\n",
    "\n",
    "Generally GPUs aren't the bottleneck of machine learning code.\n",
    "\n",
    "Data loading is the main bottleneck.\n",
    "\n",
    "As in, the transfer speed from CPU to GPU.\n",
    "\n",
    "As we're discussed before you want to get your data to the GPU as fast as possible.\n",
    "\n",
    "Let's create our `DataLoaders` using `torch.utils.data.DataLoader`.\n",
    "\n",
    "We'll set their `batch_size` to the `BATCH_SIZE` we created earlier.\n",
    "\n",
    "And the `num_workers` parameter to be the number of CPU cores we have available with `os.cpu_count()`.\n",
    "\n",
    "> **Note:** You may want to experiment with different values for `num_workers` to see what works best for your specific GPU and CPU setup. In my experience, more is better but some people have found this [generally caps out](https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/3) at `4 * number_of_gpus_you_have`, for example, `num_workers = 4 * 1` for 1 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 391 batches of size 128\n",
      "Test dataloader length: 79 batches of size 128\n",
      "Using number of workers: 16 (generally more workers means faster dataloading from CPU to GPU)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "import os\n",
    "NUM_WORKERS = os.cpu_count() # <- use all available CPU cores (this number can be tweaked through experimentation but generally more workers means faster dataloading from CPU to GPU)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Using number of workers: {NUM_WORKERS} (generally more workers means faster dataloading from CPU to GPU)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Create training loops\n",
    "\n",
    "Dataloaders ready!\n",
    "\n",
    "Let's now create some training and testing loops.\n",
    "\n",
    "These will be the same training and testing loops we created in [05. PyTorch Going Modular](https://www.learnpytorch.io/05_pytorch_going_modular/) with some slight modifications.\n",
    "\n",
    "Since we're focused on measuring speed, we're going to add a timing component to each loop to measure how long each takes to complete.\n",
    "\n",
    "We'll do this by measuring the start and end time of each training and testing epoch with Python's [`time.time()`](https://docs.python.org/3/library/time.html#time.time) and tracking it in a dictionary.\n",
    "\n",
    "> **Note:** One thing I found when experimenting with PyTorch 2.0 is that [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) produced errors in the testing loop. So I've changed it to be [`torch.no_grad()`](https://pytorch.org/docs/stable/generated/torch.no_grad.html) which offers similar functionality but is an older method than `torch.inference_mode()`. If you find that `torch.inference_mode()` works for you, please [let me know on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/discussions) and I'll update this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0, I found some errors with `torch.inference_mode()`, please let me know if this is not the case\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Train model\n",
    "\n",
    "Training and testing functions ready!\n",
    "\n",
    "Time to start training/evaluating and timing our model.\n",
    "\n",
    "We'll start with the first experiment. \n",
    "\n",
    "### Experiment 1 - Single run, no compile\n",
    "\n",
    "For experiment 1, we'll use the following parameters: \n",
    "\n",
    "| **Experiment** | **Model** | **Data** | **Epochs** | **Batch size** | **Image size** | **`torch.compile()`** |  \n",
    "|----- |-----| -----| -----| -----| -----| -----|\n",
    "| 1 (single run) | ResNet50 | CIFAR10 | 5 | 128 | 224 | No |\n",
    "\n",
    "We'll set the number of epochs to 5 and use a learning rate of `0.003` throughout (you can experiment with different learning rates for better results but we're focused on speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs as a constant\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Set the learning rate as a constant (this can be changed to get better results but for now we're just focused on time)\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9be8cdba9364e23a62a97f5f9ce2388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f25a7b05b8423dabdb3f8520881faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c9492422c04cb3ac02124e510e8733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.7892 | train_acc: 0.7289 | test_loss: 0.6578 | test_acc: 0.7734 | train_epoch_time: 184.4421 | test_epoch_time: 12.8152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f218b734aaa34b48b9b0e267ecca299d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5904f1d30ed9407f8a9502ae754e581e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4333 | train_acc: 0.8504 | test_loss: 0.5298 | test_acc: 0.8328 | train_epoch_time: 185.0387 | test_epoch_time: 12.8743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6091e74cff4b5484f1cfeb40300b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2126705b48b44c9d87aa0b21ea844d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.3185 | train_acc: 0.8898 | test_loss: 0.4445 | test_acc: 0.8500 | train_epoch_time: 185.2415 | test_epoch_time: 12.8688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2748149a06e143e08554045cc6d74cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2110702b7ac346f6971da72873b14a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.2302 | train_acc: 0.9208 | test_loss: 0.3821 | test_acc: 0.8785 | train_epoch_time: 185.3861 | test_epoch_time: 12.9847\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd3eec71f16457eb0c5a3d6e245a7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc66d67993543d098df722c7996e763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1781 | train_acc: 0.9382 | test_loss: 0.3654 | test_acc: 0.8809 | train_epoch_time: 185.3733 | test_epoch_time: 13.0048\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Train model and track results\n",
    "single_run_no_compile_results = train(model=model,\n",
    "                                      train_dataloader=train_dataloader,\n",
    "                                      test_dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      optimizer=optimizer,\n",
    "                                      epochs=NUM_EPOCHS,\n",
    "                                      device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Single run, with compile\n",
    "\n",
    "Now we'll do the same experiment but this time we'll use `torch.compile()`.\n",
    "\n",
    "| **Experiment** | **Model** | **Data** | **Epochs** | **Batch size** | **Image size** | **`torch.compile()`** |  \n",
    "|----- |-----| -----| -----| -----| -----| -----|\n",
    "| 2 (single run) | ResNet50 | CIFAR10 | 5 | 128 | 224 | Yes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.004138469696044922 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097319efc2e04ba09ad39a19c830608e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b7f3229eb742eca93273cb92ce63d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dcc2297bf34c84ad59133133e06188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.7763 | train_acc: 0.7314 | test_loss: 0.6360 | test_acc: 0.7787 | train_epoch_time: 197.0992 | test_epoch_time: 21.7807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023e58275ea04830991c859ab6757f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208ac16574e3418cb875bc108e76974b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4318 | train_acc: 0.8528 | test_loss: 0.4533 | test_acc: 0.8450 | train_epoch_time: 169.5694 | test_epoch_time: 10.8906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7c64f274d84114b27c2262ea5f04f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983a0118d0374b598500122bb09467f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.3086 | train_acc: 0.8932 | test_loss: 0.4169 | test_acc: 0.8568 | train_epoch_time: 170.2227 | test_epoch_time: 10.9187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1a8c4e59cc4cfc994bf14f78b7817f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab8e0a3e7124dce8f21b456fb0eef35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.2292 | train_acc: 0.9199 | test_loss: 0.3781 | test_acc: 0.8712 | train_epoch_time: 170.2784 | test_epoch_time: 10.9095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8694d5310fd3454d8c70bdcb0b86a088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df515a13450041fbbd7952819e959554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1700 | train_acc: 0.9409 | test_loss: 0.4632 | test_acc: 0.8581 | train_epoch_time: 170.1743 | test_epoch_time: 10.8766\n"
     ]
    }
   ],
   "source": [
    "# Create model and transforms\n",
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Compile the model and time how long it takes\n",
    "compile_start_time = time.time()\n",
    "\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "# Train the compiled model\n",
    "single_run_compile_results = train(model=compiled_model,\n",
    "                                   train_dataloader=train_dataloader,\n",
    "                                   test_dataloader=test_dataloader,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   optimizer=optimizer,\n",
    "                                   epochs=NUM_EPOCHS,\n",
    "                                   device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results of experiment 1 and 2\n",
    "\n",
    "Now we've got two trained models:\n",
    "1. One without `torch.compile()`.\n",
    "2. One with `torch.compile()`.\n",
    "\n",
    "Let's compare the results of each experiment.\n",
    "\n",
    "To do so, we'll first create dataframes of the results of each.\n",
    "\n",
    "Then we'll plot the results of each experiment on a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn experiment results into dataframes\n",
    "import pandas as pd\n",
    "single_run_no_compile_results_df = pd.DataFrame(single_run_no_compile_results)\n",
    "single_run_compile_results_df = pd.DataFrame(single_run_compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789213</td>\n",
       "      <td>0.728940</td>\n",
       "      <td>0.657841</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>184.442051</td>\n",
       "      <td>12.815214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433253</td>\n",
       "      <td>0.850380</td>\n",
       "      <td>0.529803</td>\n",
       "      <td>0.832773</td>\n",
       "      <td>185.038681</td>\n",
       "      <td>12.874254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318463</td>\n",
       "      <td>0.889754</td>\n",
       "      <td>0.444485</td>\n",
       "      <td>0.849980</td>\n",
       "      <td>185.241543</td>\n",
       "      <td>12.868787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230215</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.382118</td>\n",
       "      <td>0.878461</td>\n",
       "      <td>185.386102</td>\n",
       "      <td>12.984680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178075</td>\n",
       "      <td>0.938195</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.880934</td>\n",
       "      <td>185.373268</td>\n",
       "      <td>13.004758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.789213   0.728940   0.657841  0.773438        184.442051   \n",
       "1    0.433253   0.850380   0.529803  0.832773        185.038681   \n",
       "2    0.318463   0.889754   0.444485  0.849980        185.241543   \n",
       "3    0.230215   0.920776   0.382118  0.878461        185.386102   \n",
       "4    0.178075   0.938195   0.365407  0.880934        185.373268   \n",
       "\n",
       "   test_epoch_time  \n",
       "0        12.815214  \n",
       "1        12.874254  \n",
       "2        12.868787  \n",
       "3        12.984680  \n",
       "4        13.004758  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the head of one of the results dataframes\n",
    "single_run_no_compile_results_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got the results!\n",
    "\n",
    "Now let's write a function to take in the results and compare them with a bar chart.\n",
    "\n",
    "We'll add some metadata to the function so it can display some information about the experiments.\n",
    "\n",
    "Namely all of the parameters in our experiment setup:\n",
    "* The dataset name.\n",
    "* The model name.\n",
    "* The number of epochs.\n",
    "* The batch size.\n",
    "* The image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename to save the results\n",
    "DATASET_NAME = \"CIFAR10\"\n",
    "MODEL_NAME = \"ResNet50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_mean_epoch_times(non_compiled_results: pd.DataFrame, \n",
    "                          compiled_results: pd.DataFrame, \n",
    "                          multi_runs: bool=False, \n",
    "                          num_runs: int=0, \n",
    "                          save: bool=False, \n",
    "                          save_path: str=\"\",\n",
    "                          dataset_name: str=DATASET_NAME,\n",
    "                          model_name: str=MODEL_NAME,\n",
    "                          num_epochs: int=NUM_EPOCHS,\n",
    "                          image_size: int=IMAGE_SIZE,\n",
    "                          batch_size: int=BATCH_SIZE) -> plt.figure:\n",
    "    \n",
    "    # Get the mean epoch times from the non-compiled models\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    # Get the mean epoch times from the compiled models\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both compiled and non-compiled models\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "\n",
    "    # Create the title based on the parameters passed to the function\n",
    "    if multi_runs:\n",
    "        plt.suptitle(\"Multiple run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} ({num_runs} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    else:\n",
    "        plt.suptitle(\"Single run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    plt.legend();\n",
    "\n",
    "    # Save the figure\n",
    "    if save:\n",
    "        assert save_path != \"\", \"Please specify a save path to save the model figure to via the save_path parameter.\"\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot function ready!\n",
    "\n",
    "Let's create a directory to store our figures in and then plot the results of our first two experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Save path for single run results: pytorch_2_results/figures/single_run_NVIDIA_TITAN_RTX_ResNet50_CIFAR10_224_train_epoch_time.png\n",
      "Mean train epoch time difference: -5.201% (negative means faster)\n",
      "Mean test epoch time difference: 1.283% (negative means faster)\n",
      "[INFO] Plot saved to pytorch_2_results/figures/single_run_NVIDIA_TITAN_RTX_ResNet50_CIFAR10_224_train_epoch_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create directory for saving figures\n",
    "import os\n",
    "dir_to_save_figures_in = \"pytorch_2_results/figures/\" \n",
    "os.makedirs(dir_to_save_figures_in, exist_ok=True)\n",
    "\n",
    "# Create a save path for the single run results\n",
    "save_path_multi_run = f\"{dir_to_save_figures_in}single_run_{GPU_NAME}_{MODEL_NAME}_{DATASET_NAME}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "print(f\"[INFO] Save path for single run results: {save_path_multi_run}\")\n",
    "\n",
    "# Plot the results and save the figures\n",
    "plot_mean_epoch_times(non_compiled_results=single_run_no_compile_results_df, \n",
    "                      compiled_results=single_run_compile_results_df, \n",
    "                      multi_runs=False, \n",
    "                      save_path=save_path_multi_run, \n",
    "                      save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Save the single results to file with GPU details\n",
    "\n",
    "We can save the raw data of our results to file too by exporting the dataframes as CSVs.\n",
    "\n",
    "We'll first create a directory for storing results.\n",
    "\n",
    "Then we'll create filepaths to save each of the target dataframes to before exporting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Create filenames for each of the dataframes\n",
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME.replace(' ', '_')}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME.replace(' ', '_')}.csv\"\n",
    "\n",
    "# Create filepaths to save the results to\n",
    "single_run_no_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\"\n",
    "single_run_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\"\n",
    "print(f\"[INFO] Saving non-compiled results to: {single_run_no_compile_save_path}\")\n",
    "print(f\"[INFO] Saving compiled results to: {single_run_compile_save_path}\")\n",
    "\n",
    "# Save the results\n",
    "single_run_no_compile_results_df.to_csv(single_run_no_compile_save_path)\n",
    "single_run_compile_results_df.to_csv(single_run_compile_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Try for multiple runs\n",
    "\n",
    "UPTOHERE\n",
    "* Create function to run multiple experiments\n",
    "    * One function for non_compiled: creates non_compiled model and trains it\n",
    "    * Two functions for compiled (prevents a new compile everytime the model is trained):\n",
    "        * 1: Creates compiled model\n",
    "        * 2: Trains compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    return results\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# TK - the first time you compile a model, the first few epochs will be slower than subsequent runs\n",
    "# TK - consider the first few epochs of training to be a \"warmup\" period\n",
    "# def create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "#     model, transforms = create_model()\n",
    "#     model.to(device)\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                  lr=0.003)\n",
    "    \n",
    "#     compile_start_time = time.time()\n",
    "#     ### New in PyTorch 2.x ###\n",
    "#     compiled_model = torch.compile(model)\n",
    "#     ##########################\n",
    "#     compile_end_time = time.time()\n",
    "#     compile_time = compile_end_time - compile_start_time\n",
    "#     print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "#     compile_results = train(model=compiled_model,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             test_dataloader=test_dataloader,\n",
    "#                             loss_fn=loss_fn,\n",
    "#                             optimizer=optimizer,\n",
    "#                             epochs=NUM_EPOCHS,\n",
    "#                             device=device,\n",
    "#                             disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "#     return compile_results\n",
    "\n",
    "def create_compiled_model():\n",
    "    model, _ = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    compile_start_time = time.time()\n",
    "    ### New in PyTorch 2.x ###\n",
    "    compiled_model = torch.compile(model)\n",
    "    ##########################\n",
    "    compile_end_time = time.time()\n",
    "    compile_time = compile_end_time - compile_start_time\n",
    "    print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "    return compiled_model\n",
    "\n",
    "def train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
    "                                 lr=0.003)\n",
    "    \n",
    "    compile_results = train(model=model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=epochs,\n",
    "                            device=device,\n",
    "                            disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "    return compile_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Experiment 3 - Multiple runs, no compile\n",
    "\n",
    "| **Experiment** | **Model** | **Data** | **Epochs** | **Batch size** | **Image size** | **`torch.compile()`** |  \n",
    "|----- |-----| -----| -----| -----| -----| -----|\n",
    "| 3 (multi-run) | ResNet50 | CIFAR10 | 3x5 | 128 | 224 | No |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563efc283b8b475790f71c74571cd90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.8378 | train_acc: 0.7089 | test_loss: 1.0247 | test_acc: 0.6870 | train_epoch_time: 109.5564 | test_epoch_time: 9.2328\n",
      "Epoch: 2 | train_loss: 0.4580 | train_acc: 0.8411 | test_loss: 0.5060 | test_acc: 0.8253 | train_epoch_time: 109.5725 | test_epoch_time: 9.2088\n",
      "Epoch: 3 | train_loss: 0.3323 | train_acc: 0.8846 | test_loss: 0.4765 | test_acc: 0.8399 | train_epoch_time: 109.5022 | test_epoch_time: 9.1758\n",
      "Epoch: 4 | train_loss: 0.2509 | train_acc: 0.9146 | test_loss: 0.4185 | test_acc: 0.8649 | train_epoch_time: 109.5430 | test_epoch_time: 9.1935\n",
      "Epoch: 5 | train_loss: 0.1788 | train_acc: 0.9376 | test_loss: 0.4003 | test_acc: 0.8716 | train_epoch_time: 109.5906 | test_epoch_time: 9.1582\n",
      "[INFO] Run 2 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.8725 | train_acc: 0.6948 | test_loss: 0.6809 | test_acc: 0.7659 | train_epoch_time: 109.5877 | test_epoch_time: 9.2452\n",
      "Epoch: 2 | train_loss: 0.4765 | train_acc: 0.8357 | test_loss: 0.5766 | test_acc: 0.8007 | train_epoch_time: 109.4739 | test_epoch_time: 9.2453\n",
      "Epoch: 3 | train_loss: 0.3369 | train_acc: 0.8838 | test_loss: 0.3794 | test_acc: 0.8704 | train_epoch_time: 109.5909 | test_epoch_time: 9.2295\n",
      "Epoch: 4 | train_loss: 0.2466 | train_acc: 0.9138 | test_loss: 0.5049 | test_acc: 0.8333 | train_epoch_time: 109.5572 | test_epoch_time: 9.2202\n",
      "Epoch: 5 | train_loss: 0.1788 | train_acc: 0.9372 | test_loss: 0.4328 | test_acc: 0.8614 | train_epoch_time: 109.5400 | test_epoch_time: 9.2429\n",
      "[INFO] Run 3 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.7792 | train_acc: 0.7307 | test_loss: 0.6573 | test_acc: 0.7762 | train_epoch_time: 109.6908 | test_epoch_time: 9.2283\n",
      "Epoch: 2 | train_loss: 0.4296 | train_acc: 0.8538 | test_loss: 0.6004 | test_acc: 0.8050 | train_epoch_time: 109.5275 | test_epoch_time: 9.2120\n",
      "Epoch: 3 | train_loss: 0.3101 | train_acc: 0.8926 | test_loss: 0.4222 | test_acc: 0.8589 | train_epoch_time: 109.6433 | test_epoch_time: 9.1418\n",
      "Epoch: 4 | train_loss: 0.2354 | train_acc: 0.9186 | test_loss: 0.3736 | test_acc: 0.8787 | train_epoch_time: 109.5805 | test_epoch_time: 9.2719\n",
      "Epoch: 5 | train_loss: 0.1736 | train_acc: 0.9386 | test_loss: 0.3786 | test_acc: 0.8789 | train_epoch_time: 109.6146 | test_epoch_time: 9.2244\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "NUM_RUNS = 3\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "non_compile_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829813</td>\n",
       "      <td>0.711462</td>\n",
       "      <td>0.787613</td>\n",
       "      <td>0.743045</td>\n",
       "      <td>109.611609</td>\n",
       "      <td>9.235445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454694</td>\n",
       "      <td>0.843546</td>\n",
       "      <td>0.560969</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>109.524597</td>\n",
       "      <td>9.222032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.326421</td>\n",
       "      <td>0.887027</td>\n",
       "      <td>0.426016</td>\n",
       "      <td>0.856375</td>\n",
       "      <td>109.578773</td>\n",
       "      <td>9.182378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.915669</td>\n",
       "      <td>0.432327</td>\n",
       "      <td>0.858946</td>\n",
       "      <td>109.560207</td>\n",
       "      <td>9.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177081</td>\n",
       "      <td>0.937800</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>0.870616</td>\n",
       "      <td>109.581744</td>\n",
       "      <td>9.208528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.829813   0.711462   0.787613  0.743045        109.611609   \n",
       "1    0.454694   0.843546   0.560969  0.810324        109.524597   \n",
       "2    0.326421   0.887027   0.426016  0.856375        109.578773   \n",
       "3    0.244295   0.915669   0.432327  0.858946        109.560207   \n",
       "4    0.177081   0.937800   0.403896  0.870616        109.581744   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         9.235445  \n",
       "1         9.222032  \n",
       "2         9.182378  \n",
       "3         9.228536  \n",
       "4         9.208528  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Experiment 4 - Multiple runs, with compile\n",
    "\n",
    "| **Experiment** | **Model** | **Data** | **Epochs** | **Batch size** | **Image size** | **`torch.compile()`** |  \n",
    "|----- |-----| -----| -----| -----| -----| -----|\n",
    "| 4 (multi-run) | ResNet50 | CIFAR10 | 3x5 | 128 | 224 | Yes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.001680135726928711 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de82acde240441785f9e55049a8b9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.7646 | train_acc: 0.7342 | test_loss: 0.7037 | test_acc: 0.7672 | train_epoch_time: 122.2336 | test_epoch_time: 16.7382\n",
      "Epoch: 2 | train_loss: 0.4172 | train_acc: 0.8569 | test_loss: 0.4448 | test_acc: 0.8516 | train_epoch_time: 97.6691 | test_epoch_time: 7.5259\n",
      "Epoch: 3 | train_loss: 0.3056 | train_acc: 0.8939 | test_loss: 0.4070 | test_acc: 0.8654 | train_epoch_time: 97.6748 | test_epoch_time: 7.4222\n",
      "Epoch: 4 | train_loss: 0.2275 | train_acc: 0.9221 | test_loss: 0.4287 | test_acc: 0.8588 | train_epoch_time: 97.6403 | test_epoch_time: 7.4536\n",
      "Epoch: 5 | train_loss: 0.1673 | train_acc: 0.9409 | test_loss: 0.3591 | test_acc: 0.8873 | train_epoch_time: 97.6284 | test_epoch_time: 7.4502\n",
      "[INFO] Run 2 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.1867 | train_acc: 0.9353 | test_loss: 0.3929 | test_acc: 0.8778 | train_epoch_time: 97.7071 | test_epoch_time: 7.4878\n",
      "Epoch: 2 | train_loss: 0.1211 | train_acc: 0.9578 | test_loss: 0.3603 | test_acc: 0.8928 | train_epoch_time: 97.5929 | test_epoch_time: 7.4256\n",
      "Epoch: 3 | train_loss: 0.0917 | train_acc: 0.9682 | test_loss: 0.4029 | test_acc: 0.8845 | train_epoch_time: 97.7499 | test_epoch_time: 7.4274\n",
      "Epoch: 4 | train_loss: 0.0708 | train_acc: 0.9749 | test_loss: 0.4205 | test_acc: 0.8841 | train_epoch_time: 97.6956 | test_epoch_time: 7.4811\n",
      "Epoch: 5 | train_loss: 0.0560 | train_acc: 0.9807 | test_loss: 0.4884 | test_acc: 0.8682 | train_epoch_time: 97.8197 | test_epoch_time: 7.4636\n",
      "[INFO] Run 3 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.0706 | train_acc: 0.9757 | test_loss: 0.4214 | test_acc: 0.8836 | train_epoch_time: 97.8444 | test_epoch_time: 7.5171\n",
      "Epoch: 2 | train_loss: 0.0509 | train_acc: 0.9825 | test_loss: 0.4852 | test_acc: 0.8805 | train_epoch_time: 97.6679 | test_epoch_time: 7.5124\n",
      "Epoch: 3 | train_loss: 0.0425 | train_acc: 0.9851 | test_loss: 0.4100 | test_acc: 0.8985 | train_epoch_time: 97.6812 | test_epoch_time: 7.4985\n",
      "Epoch: 4 | train_loss: 0.0410 | train_acc: 0.9859 | test_loss: 0.4030 | test_acc: 0.9010 | train_epoch_time: 97.7047 | test_epoch_time: 7.4856\n",
      "Epoch: 5 | train_loss: 0.0394 | train_acc: 0.9864 | test_loss: 0.4396 | test_acc: 0.8923 | train_epoch_time: 97.6329 | test_epoch_time: 7.5252\n"
     ]
    }
   ],
   "source": [
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# Create compiled model\n",
    "compiled_model = create_compiled_model()\n",
    "\n",
    "compiled_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for compiled model\")\n",
    "    results = train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.340599</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.505985</td>\n",
       "      <td>0.842860</td>\n",
       "      <td>105.928343</td>\n",
       "      <td>10.581059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.196404</td>\n",
       "      <td>0.932397</td>\n",
       "      <td>0.430130</td>\n",
       "      <td>0.874967</td>\n",
       "      <td>97.643334</td>\n",
       "      <td>7.487950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146588</td>\n",
       "      <td>0.949077</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>97.701943</td>\n",
       "      <td>7.449384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113085</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.417372</td>\n",
       "      <td>0.881296</td>\n",
       "      <td>97.680187</td>\n",
       "      <td>7.473454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087548</td>\n",
       "      <td>0.969324</td>\n",
       "      <td>0.429059</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>97.693671</td>\n",
       "      <td>7.479675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.340599   0.881720   0.505985  0.842860        105.928343   \n",
       "1    0.196404   0.932397   0.430130  0.874967         97.643334   \n",
       "2    0.146588   0.949077   0.406647  0.882812         97.701943   \n",
       "3    0.113085   0.960947   0.417372  0.881296         97.680187   \n",
       "4    0.087548   0.969324   0.429059  0.882582         97.693671   \n",
       "\n",
       "   test_epoch_time  \n",
       "0        10.581059  \n",
       "1         7.487950  \n",
       "2         7.449384  \n",
       "3         7.473454  \n",
       "4         7.479675  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean()\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_epoch_times(non_compiled_results, compiled_results, multi_runs=False, num_runs=0, save=False, save_path=\"\"):\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "    # Make both bars appear on the same plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "    # TK - make this title include dataset/model information for a better idea of what's happening\n",
    "    if multi_runs:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} ({NUM_RUNS} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    else:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    plt.legend();\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train epoch time difference: -9.347% (negative means faster)\n",
      "Mean test epoch time difference: -12.165% (negative means faster)\n",
      "[INFO] Plot saved to pytorch_2_results/figures/multi_run_NVIDIA GeForce RTX 4080_ResNet50_CIFAR10_224_train_epoch_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"pytorch_2_results/figures\", exist_ok=True)\n",
    "save_path_multi_run = f\"pytorch_2_results/figures/multi_run_{gpu_name}_{model_name}_{dataset_name}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "plot_mean_epoch_times(non_compile_results_multiple_runs_df, compile_results_multiple_runs_df, multi_runs=True, num_runs=NUM_RUNS, save_path=save_path_multi_run, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_run_non_compiled_results_3_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n",
      "multi_run_compiled_results_3_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n"
     ]
    }
   ],
   "source": [
    "save_name_for_multi_run_non_compiled_results = f\"multi_run_non_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_multi_run_compiled_results = f\"multi_run_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "print(save_name_for_multi_run_non_compiled_results)\n",
    "print(save_name_for_multi_run_compiled_results)\n",
    "\n",
    "# Make a directory for multi_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_multi_run_results_dir = f\"{pytorch_2_results_dir}/multi_run_results\"\n",
    "os.makedirs(pytorch_2_multi_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Possible improvements/extensions\n",
    "\n",
    "* TK - use mixed precision training - https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples (more speedups)\n",
    "* Transformer based models may see better speedups than conv models (due to PyTorch 2.0) - https://pytorch.org/blog/pytorch-2.0-release/#stable-accelerated-pytorch-2-transformers "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Resources to learn more\n",
    "\n",
    "I've found the following resources to be helpful learning about PyTorch 2.0 and it's upcoming features.\n",
    "\n",
    "* [PyTorch 2.0 launch blog post](https://pytorch.org/get-started/pytorch-2.0/). \n",
    "* [PyTorch 2.0 release notes](https://pytorch.org/blog/pytorch-2.0-release/) (blog post).\n",
    "    * As well as the [GitHub release notes](https://github.com/pytorch/pytorch/releases/tag/v2.0.0) (lots of info here!).\n",
    "* [PyTorch default device context manager docs](https://github.com/pytorch/tutorials/pull/2220/files).\n",
    "* [PyTorch 2.0 video introduction on YouTube](https://youtu.be/WqLKfta5Ijw) (created by yours truly).\n",
    "* See a [tip by Sebastian Raschka](https://twitter.com/rasbt/status/1638297626385719297?s=20) to improve `torch.compile()` by performing an example batch first (warm-up the model) before continuing with further training (this explains the increased speedups with multiple runs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
