{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: A Quick PyTorch 2.0 Tutorial\n",
    "\n",
    "In short:\n",
    "\n",
    "If you have a new GPU (NVIDIA 40XX or A100, A10G etc), you can \"compile\" your models and often see speed ups.\n",
    "\n",
    "**Before PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "### Train model ###\n",
    "\n",
    "### Test model ###\n",
    "```\n",
    "\n",
    "**After PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "compiled_model = torch.compile(model) # <- new!\n",
    "\n",
    "### Train model ### <- faster!\n",
    "\n",
    "### Test model ### <- faster!\n",
    "```\n",
    "\n",
    "Things to note:\n",
    "* TK - add where it doesn't work\n",
    "\n",
    "## TK - Resources to learn more\n",
    "* PyTorch 2.0 launch blog post - https://pytorch.org/get-started/pytorch-2.0/ \n",
    "* PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/ \n",
    "    * GitHub release notes - https://github.com/pytorch/pytorch/releases/tag/v2.0.0 (lots of info here!)\n",
    "* PyTorch default device context manager - https://github.com/pytorch/tutorials/pull/2220/files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current PyTorch version: 2.0.0+cu118 (should be 2.x+)\n",
      "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 if necessary\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - New feature: globally set devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# See here: https://github.com/pytorch/tutorials/pull/2220/files \n",
    "import torch\n",
    "with torch.device('cuda'):\n",
    "    mod = torch.nn.Linear(20, 30)\n",
    "    print(mod.weight.device)\n",
    "    print(mod(torch.randn(128, 20)).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* add in info about PyTorch 2.0\n",
    "* a quick upgrade for speed ups\n",
    "* a quick note on which GPU will be needed (works best on NVIDIA GPUs, not macOS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Check GPU\n",
    "\n",
    "* **Note:** If you're running on Google Colab, you'll need to setup a GPU: runtime -> change runtime type -> hardware accelerator\n",
    "* Best speedups are on newer NVIDIA/AMD GPUs (this is because PyTorch 2.0 leverages new GPU hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU information:\n",
      "Thu Mar 16 14:04:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   47C    P2    36W / 320W |    371MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1001      G   /usr/lib/xorg/Xorg                 86MiB |\n",
      "|    0   N/A  N/A      1223      G   /usr/bin/gnome-shell               10MiB |\n",
      "|    0   N/A  N/A     79988      C   ...ch/env-nightly/bin/python      270MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU name: NVIDIA GeForce RTX 4080\n",
      "GPU capability score: (8, 9)\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  print(f'GPU name: {gpu_name}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  gpu_score = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {gpu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TK - add a table for NVIDIA GPUs and architectures etc and which lead to speedups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Simple training example \n",
    "\n",
    "* CIFAR10\n",
    "* ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision version: 0.15.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25557032\n"
     ]
    }
   ],
   "source": [
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "transforms = model_weights.transforms()\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU with score: (8, 9), enabling TensorFloat32 (TF32) computing (faster on new GPUs)\n"
     ]
    }
   ],
   "source": [
    "# TODO: speedups on larger GPUs will likely be seen with larger amounts of data\n",
    "# TK - also see here for using `torch.backends.cuda.matmul.allow_tf32` to enable TF32 on A100s/newer GPUS - https://github.com/pytorch/pytorch/blob/master/torch/_inductor/compile_fx.py#L86 \n",
    "\n",
    "if gpu_score >= (8, 0):\n",
    "  print(f\"[INFO] Using GPU with score: {gpu_score}, enabling TensorFloat32 (TF32) computing (faster on new GPUs)\")\n",
    "  # Set TF32 = True\n",
    "  IMAGE_SIZE = 224\n",
    "  torch.backends.cuda.matmul.allow_tf32 = True\n",
    "  transforms.crop_size = IMAGE_SIZE\n",
    "  transforms.resize_size = IMAGE_SIZE\n",
    "else:\n",
    "  transforms.crop_size = 224\n",
    "  transforms.resize_size = 224 # Resize to 32x32, CIFAR10 is 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=224\n",
       "    resize_size=224\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "* Generally GPUs aren't the bottleneck of ML code\n",
    "* Data loading is the main bottleneck\n",
    "    * E.g. you want to get your data to the GPU as fast as possible = more workers (though in my experience this generally caps at about ~4 workers per GPU, though don't trust me, better to do your own experiments)\n",
    "* You want your GPUs to go brrrrr - https://horace.io/brrr_intro.html \n",
    "    * More here on crazy matmul improvements - https://twitter.com/cHHillee/status/1630274804795445248?s=20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 391 batches of size 128\n",
      "Test dataloader length: 79 batches of size 128\n",
      "Using number of workers: 16 (generally more workers means faster dataloading from CPU to GPU)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "import os\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Using number of workers: {NUM_WORKERS} (generally more workers means faster dataloading from CPU to GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename to save the results\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_name = \"ResNet50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "def create_model():\n",
    "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "  # TK - adjust the output layer shape for CIFAR10\n",
    "  model.fc = torch.nn.Linear(2048, 10)\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28e8225c6c3449a8eb1d9bb4fabb478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e34c9d1a07844498d369afe485d8c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.1420588493347168 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d15f005c04a6f9d4d198c24167be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea547dbc527489b8d0ca06c3ef91ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff49a241237f4e7b8f8ed9e8600771e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.7884 | train_acc: 0.7266 | test_loss: 0.9223 | test_acc: 0.6968 | train_epoch_time: 123.8277 | test_epoch_time: 17.1039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477904cc54294d36a836ae708d4e83ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237dab2f5c44316ab12068a6839c89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4473 | train_acc: 0.8468 | test_loss: 0.5589 | test_acc: 0.8085 | train_epoch_time: 98.2803 | test_epoch_time: 7.5258\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "compile_start_time = time.time()\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "compile_results = train(model=compiled_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before tf32 (with compile)\n",
    "# Epoch: 2 | train_loss: 0.4303 | train_acc: 0.8524 | test_loss: 0.5928 | test_acc: 0.7969 | train_epoch_time: 98.1773 | test_epoch_time: 7.5189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graphs of results and compiled_results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "compile_results_df = pd.DataFrame(compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.014732</td>\n",
       "      <td>0.664734</td>\n",
       "      <td>0.940400</td>\n",
       "      <td>0.696005</td>\n",
       "      <td>8.323442</td>\n",
       "      <td>0.909204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647204</td>\n",
       "      <td>0.787268</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>0.754055</td>\n",
       "      <td>8.015560</td>\n",
       "      <td>0.854492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.014732   0.664734   0.940400  0.696005          8.323442   \n",
       "1    0.647204   0.787268   0.762655  0.754055          8.015560   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         0.909204  \n",
       "1         0.854492  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Make this more obvious that it's for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_train_epoch_time = results_df.train_epoch_time.mean()\n",
    "mean_test_epoch_time = results_df.test_epoch_time.mean()\n",
    "mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "mean_compile_train_epoch_time = compile_results_df.train_epoch_time.mean()\n",
    "mean_compile_test_epoch_time = compile_results_df.test_epoch_time.mean()\n",
    "mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "# Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "# Make both bars appear on the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "width = 0.3\n",
    "x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "# TK - make this title include dataset/model information for a better idea of what's happening\n",
    "plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) on {gpu_name} | {dataset_name} | {model_name} | Image size: {IMAGE_SIZE}\")\n",
    "plt.legend();\n",
    "\n",
    "# mean_train_epoch_time, mean_compile_train_epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8818479776382446, 5.8400315046310425)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_epoch_time, mean_compile_test_epoch_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Save results to file with GPU details\n",
    "\n",
    "TODO:\n",
    "* Save the results to file with GPU name and other details (run on multiple machines)\n",
    "* Run for multiple passes (e.g. 5x runs to average the time over each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv',\n",
       " 'single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_non_compiled_results, save_name_for_compiled_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Try for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    return results\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# TK - the first time you compile a model, the first few epochs will be slower than subsequent runs\n",
    "# TK - consider the first few epochs of training to be a \"warmup\" period\n",
    "# def create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "#     model, transforms = create_model()\n",
    "#     model.to(device)\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                  lr=0.003)\n",
    "    \n",
    "#     compile_start_time = time.time()\n",
    "#     ### New in PyTorch 2.x ###\n",
    "#     compiled_model = torch.compile(model)\n",
    "#     ##########################\n",
    "#     compile_end_time = time.time()\n",
    "#     compile_time = compile_end_time - compile_start_time\n",
    "#     print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "#     compile_results = train(model=compiled_model,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             test_dataloader=test_dataloader,\n",
    "#                             loss_fn=loss_fn,\n",
    "#                             optimizer=optimizer,\n",
    "#                             epochs=NUM_EPOCHS,\n",
    "#                             device=device,\n",
    "#                             disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "#     return compile_results\n",
    "\n",
    "def create_compiled_model():\n",
    "    model, _ = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    compile_start_time = time.time()\n",
    "    ### New in PyTorch 2.x ###\n",
    "    compiled_model = torch.compile(model)\n",
    "    ##########################\n",
    "    compile_end_time = time.time()\n",
    "    compile_time = compile_end_time - compile_start_time\n",
    "    print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "    return compiled_model\n",
    "\n",
    "def train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
    "                                 lr=0.003)\n",
    "    \n",
    "    compile_results = train(model=model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=epochs,\n",
    "                            device=device,\n",
    "                            disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "    return compile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9835c5b8fc26404487b1928838e6aa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.9933 | train_acc: 0.6741 | test_loss: 0.8777 | test_acc: 0.7114 | train_epoch_time: 7.9072 | test_epoch_time: 0.9039\n",
      "Epoch: 2 | train_loss: 0.6507 | train_acc: 0.7840 | test_loss: 0.6979 | test_acc: 0.7748 | train_epoch_time: 8.1106 | test_epoch_time: 0.9042\n",
      "Epoch: 3 | train_loss: 0.7647 | train_acc: 0.7528 | test_loss: 0.8412 | test_acc: 0.7132 | train_epoch_time: 8.0604 | test_epoch_time: 0.8591\n",
      "Epoch: 4 | train_loss: 0.5499 | train_acc: 0.8164 | test_loss: 0.5979 | test_acc: 0.8017 | train_epoch_time: 7.7737 | test_epoch_time: 0.8944\n",
      "Epoch: 5 | train_loss: 0.3898 | train_acc: 0.8698 | test_loss: 0.6339 | test_acc: 0.7903 | train_epoch_time: 7.8392 | test_epoch_time: 0.8446\n",
      "[INFO] Run 2 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.5152 | train_acc: 0.5138 | test_loss: 1.7869 | test_acc: 0.3523 | train_epoch_time: 7.8752 | test_epoch_time: 0.9025\n",
      "Epoch: 2 | train_loss: 1.4833 | train_acc: 0.5043 | test_loss: 3.4212 | test_acc: 0.5777 | train_epoch_time: 7.9020 | test_epoch_time: 0.8985\n",
      "Epoch: 3 | train_loss: 1.2367 | train_acc: 0.5866 | test_loss: 1.1154 | test_acc: 0.6179 | train_epoch_time: 7.6131 | test_epoch_time: 0.9098\n",
      "Epoch: 4 | train_loss: 0.9363 | train_acc: 0.6785 | test_loss: 0.9315 | test_acc: 0.6788 | train_epoch_time: 7.8930 | test_epoch_time: 0.8377\n",
      "Epoch: 5 | train_loss: 0.7999 | train_acc: 0.7260 | test_loss: 0.8655 | test_acc: 0.7023 | train_epoch_time: 7.8692 | test_epoch_time: 0.9030\n",
      "[INFO] Run 3 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0174 | train_acc: 0.6618 | test_loss: 0.9512 | test_acc: 0.6681 | train_epoch_time: 7.9052 | test_epoch_time: 0.8729\n",
      "Epoch: 2 | train_loss: 0.8349 | train_acc: 0.7301 | test_loss: 3.1725 | test_acc: 0.4282 | train_epoch_time: 7.7605 | test_epoch_time: 0.8600\n",
      "Epoch: 3 | train_loss: 0.7412 | train_acc: 0.7532 | test_loss: 0.6980 | test_acc: 0.7697 | train_epoch_time: 7.8930 | test_epoch_time: 0.9174\n",
      "Epoch: 4 | train_loss: 0.5163 | train_acc: 0.8296 | test_loss: 4.4012 | test_acc: 0.5257 | train_epoch_time: 7.9044 | test_epoch_time: 0.9200\n",
      "Epoch: 5 | train_loss: 0.9666 | train_acc: 0.6797 | test_loss: 0.6742 | test_acc: 0.7754 | train_epoch_time: 7.7883 | test_epoch_time: 0.9086\n",
      "[INFO] Run 4 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.9850 | train_acc: 0.6751 | test_loss: 0.8127 | test_acc: 0.7310 | train_epoch_time: 7.7481 | test_epoch_time: 0.8988\n",
      "Epoch: 2 | train_loss: 0.6506 | train_acc: 0.7827 | test_loss: 0.7036 | test_acc: 0.7738 | train_epoch_time: 7.8897 | test_epoch_time: 0.8901\n",
      "Epoch: 3 | train_loss: 0.5238 | train_acc: 0.8247 | test_loss: 0.7921 | test_acc: 0.7500 | train_epoch_time: 7.8792 | test_epoch_time: 0.9058\n",
      "Epoch: 4 | train_loss: 0.4459 | train_acc: 0.8505 | test_loss: 0.6269 | test_acc: 0.7960 | train_epoch_time: 7.8079 | test_epoch_time: 0.8676\n",
      "Epoch: 5 | train_loss: 0.3601 | train_acc: 0.8792 | test_loss: 0.5760 | test_acc: 0.8147 | train_epoch_time: 7.9072 | test_epoch_time: 0.8612\n",
      "[INFO] Run 5 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.2415 | train_acc: 0.5939 | test_loss: 1.0566 | test_acc: 0.6631 | train_epoch_time: 7.5737 | test_epoch_time: 0.9006\n",
      "Epoch: 2 | train_loss: 0.7637 | train_acc: 0.7406 | test_loss: 0.7911 | test_acc: 0.7369 | train_epoch_time: 7.7404 | test_epoch_time: 0.8616\n",
      "Epoch: 3 | train_loss: 0.5780 | train_acc: 0.8057 | test_loss: 0.9023 | test_acc: 0.7116 | train_epoch_time: 7.6804 | test_epoch_time: 0.8711\n",
      "Epoch: 4 | train_loss: 0.5350 | train_acc: 0.8216 | test_loss: 0.7636 | test_acc: 0.7515 | train_epoch_time: 7.9258 | test_epoch_time: 0.8679\n",
      "Epoch: 5 | train_loss: 0.4159 | train_acc: 0.8612 | test_loss: 0.7219 | test_acc: 0.7774 | train_epoch_time: 7.9221 | test_epoch_time: 0.8431\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "NUM_RUNS = 5\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "non_compile_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.150492</td>\n",
       "      <td>0.623735</td>\n",
       "      <td>1.097026</td>\n",
       "      <td>0.625178</td>\n",
       "      <td>7.801876</td>\n",
       "      <td>0.895728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876652</td>\n",
       "      <td>0.708353</td>\n",
       "      <td>1.757235</td>\n",
       "      <td>0.658307</td>\n",
       "      <td>7.880623</td>\n",
       "      <td>0.882865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768877</td>\n",
       "      <td>0.744596</td>\n",
       "      <td>0.869815</td>\n",
       "      <td>0.712480</td>\n",
       "      <td>7.825229</td>\n",
       "      <td>0.892648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596688</td>\n",
       "      <td>0.799302</td>\n",
       "      <td>1.464201</td>\n",
       "      <td>0.710740</td>\n",
       "      <td>7.860939</td>\n",
       "      <td>0.877511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.586464</td>\n",
       "      <td>0.803174</td>\n",
       "      <td>0.694303</td>\n",
       "      <td>0.772033</td>\n",
       "      <td>7.865202</td>\n",
       "      <td>0.872107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.150492   0.623735   1.097026  0.625178          7.801876   \n",
       "1    0.876652   0.708353   1.757235  0.658307          7.880623   \n",
       "2    0.768877   0.744596   0.869815  0.712480          7.825229   \n",
       "3    0.596688   0.799302   1.464201  0.710740          7.860939   \n",
       "4    0.586464   0.803174   0.694303  0.772033          7.865202   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         0.895728  \n",
       "1         0.882865  \n",
       "2         0.892648  \n",
       "3         0.877511  \n",
       "4         0.872107  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.0012981891632080078 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f10724fd71416e86550758ea26d438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 1.1553 | train_acc: 0.6216 | test_loss: 1.6136 | test_acc: 0.5210 | train_epoch_time: 31.2227 | test_epoch_time: 9.8073\n",
      "Epoch: 2 | train_loss: 0.8730 | train_acc: 0.7132 | test_loss: 3.6346 | test_acc: 0.5490 | train_epoch_time: 8.4313 | test_epoch_time: 0.7731\n",
      "Epoch: 3 | train_loss: 0.9091 | train_acc: 0.7033 | test_loss: 0.7356 | test_acc: 0.7562 | train_epoch_time: 8.2109 | test_epoch_time: 0.8439\n",
      "Epoch: 4 | train_loss: 0.5899 | train_acc: 0.7999 | test_loss: 0.7572 | test_acc: 0.7550 | train_epoch_time: 8.2072 | test_epoch_time: 0.8051\n",
      "Epoch: 5 | train_loss: 0.4665 | train_acc: 0.8441 | test_loss: 0.6540 | test_acc: 0.7845 | train_epoch_time: 8.4085 | test_epoch_time: 0.8039\n",
      "[INFO] Run 2 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.6554 | train_acc: 0.7915 | test_loss: 1.5943 | test_acc: 0.6423 | train_epoch_time: 8.7771 | test_epoch_time: 0.8431\n",
      "Epoch: 2 | train_loss: 0.9463 | train_acc: 0.7022 | test_loss: 0.7139 | test_acc: 0.7756 | train_epoch_time: 8.2768 | test_epoch_time: 0.8050\n",
      "Epoch: 3 | train_loss: 0.5263 | train_acc: 0.8295 | test_loss: 0.6307 | test_acc: 0.7959 | train_epoch_time: 8.3441 | test_epoch_time: 0.8710\n",
      "Epoch: 4 | train_loss: 0.4445 | train_acc: 0.8551 | test_loss: 0.9216 | test_acc: 0.7049 | train_epoch_time: 8.5090 | test_epoch_time: 0.8280\n",
      "Epoch: 5 | train_loss: 0.6520 | train_acc: 0.7885 | test_loss: 0.6193 | test_acc: 0.7989 | train_epoch_time: 8.4680 | test_epoch_time: 0.8405\n",
      "[INFO] Run 3 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.4172 | train_acc: 0.8599 | test_loss: 0.6483 | test_acc: 0.7942 | train_epoch_time: 8.4289 | test_epoch_time: 0.8129\n",
      "Epoch: 2 | train_loss: 0.2990 | train_acc: 0.9007 | test_loss: 0.6212 | test_acc: 0.8120 | train_epoch_time: 8.4553 | test_epoch_time: 0.8387\n",
      "Epoch: 3 | train_loss: 0.2282 | train_acc: 0.9224 | test_loss: 0.6836 | test_acc: 0.8019 | train_epoch_time: 8.3994 | test_epoch_time: 0.8279\n",
      "Epoch: 4 | train_loss: 0.1819 | train_acc: 0.9399 | test_loss: 0.7388 | test_acc: 0.7991 | train_epoch_time: 8.1405 | test_epoch_time: 0.7923\n",
      "Epoch: 5 | train_loss: 0.1525 | train_acc: 0.9502 | test_loss: 0.7272 | test_acc: 0.8069 | train_epoch_time: 8.2214 | test_epoch_time: 0.8617\n",
      "[INFO] Run 4 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.1444 | train_acc: 0.9527 | test_loss: 0.7865 | test_acc: 0.8050 | train_epoch_time: 8.5123 | test_epoch_time: 0.8370\n",
      "Epoch: 2 | train_loss: 0.1133 | train_acc: 0.9607 | test_loss: 0.8810 | test_acc: 0.7995 | train_epoch_time: 8.6449 | test_epoch_time: 0.8619\n",
      "Epoch: 3 | train_loss: 0.1025 | train_acc: 0.9653 | test_loss: 0.7670 | test_acc: 0.8078 | train_epoch_time: 8.3002 | test_epoch_time: 0.9016\n",
      "Epoch: 4 | train_loss: 0.0948 | train_acc: 0.9690 | test_loss: 0.7644 | test_acc: 0.8171 | train_epoch_time: 8.5451 | test_epoch_time: 0.8578\n",
      "Epoch: 5 | train_loss: 0.0771 | train_acc: 0.9744 | test_loss: 0.7829 | test_acc: 0.8211 | train_epoch_time: 8.5347 | test_epoch_time: 0.8714\n",
      "[INFO] Run 5 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.1228 | train_acc: 0.9609 | test_loss: 0.8452 | test_acc: 0.8047 | train_epoch_time: 8.5155 | test_epoch_time: 0.8913\n",
      "Epoch: 2 | train_loss: 0.0684 | train_acc: 0.9775 | test_loss: 0.8078 | test_acc: 0.8213 | train_epoch_time: 8.7267 | test_epoch_time: 0.8657\n",
      "Epoch: 3 | train_loss: 0.0540 | train_acc: 0.9818 | test_loss: 0.9585 | test_acc: 0.8065 | train_epoch_time: 8.4797 | test_epoch_time: 0.8727\n",
      "Epoch: 4 | train_loss: 0.0649 | train_acc: 0.9788 | test_loss: 0.8791 | test_acc: 0.8105 | train_epoch_time: 8.4178 | test_epoch_time: 0.8864\n",
      "Epoch: 5 | train_loss: 1.0556 | train_acc: 0.7750 | test_loss: 1.6882 | test_acc: 0.5228 | train_epoch_time: 8.4656 | test_epoch_time: 0.8692\n"
     ]
    }
   ],
   "source": [
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# Create compiled model\n",
    "compiled_model = create_compiled_model()\n",
    "\n",
    "compiled_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for compiled model\")\n",
    "    results = train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.837326</td>\n",
       "      <td>1.097585</td>\n",
       "      <td>0.713430</td>\n",
       "      <td>13.091321</td>\n",
       "      <td>2.638317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459969</td>\n",
       "      <td>0.850869</td>\n",
       "      <td>1.331702</td>\n",
       "      <td>0.751483</td>\n",
       "      <td>8.507003</td>\n",
       "      <td>0.828881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.364020</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>0.755070</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>8.346875</td>\n",
       "      <td>0.863423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.275216</td>\n",
       "      <td>0.908541</td>\n",
       "      <td>0.812199</td>\n",
       "      <td>0.777334</td>\n",
       "      <td>8.363933</td>\n",
       "      <td>0.833921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480737</td>\n",
       "      <td>0.866452</td>\n",
       "      <td>0.894328</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>8.419635</td>\n",
       "      <td>0.849352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.499000   0.837326   1.097585  0.713430         13.091321   \n",
       "1    0.459969   0.850869   1.331702  0.751483          8.507003   \n",
       "2    0.364020   0.880461   0.755070  0.793651          8.346875   \n",
       "3    0.275216   0.908541   0.812199  0.777334          8.363933   \n",
       "4    0.480737   0.866452   0.894328  0.746835          8.419635   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         2.638317  \n",
       "1         0.828881  \n",
       "2         0.863423  \n",
       "3         0.833921  \n",
       "4         0.849352  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean()\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_epoch_times(non_compiled_results, compiled_results, multi_runs=False, num_runs=0, save=False, save_path=\"\"):\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "    # Make both bars appear on the same plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "    # TK - make this title include dataset/model information for a better idea of what's happening\n",
    "    if multi_runs:\n",
    "        plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) for {num_runs} runs | {gpu_name} | {dataset_name} | {model_name}\")\n",
    "    else:\n",
    "        plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) on {gpu_name} | {dataset_name} | {model_name}\")\n",
    "    plt.legend();\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean_epoch_times(non_compile_results_multiple_runs_df, compile_results_multiple_runs_df, multi_runs=True, num_runs=NUM_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_run_non_compiled_results_5_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n",
      "multi_run_compiled_results_5_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n"
     ]
    }
   ],
   "source": [
    "save_name_for_multi_run_non_compiled_results = f\"multi_run_non_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_multi_run_compiled_results = f\"multi_run_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "print(save_name_for_multi_run_non_compiled_results)\n",
    "print(save_name_for_multi_run_compiled_results)\n",
    "\n",
    "# Make a directory for multi_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_multi_run_results_dir = f\"{pytorch_2_results_dir}/multi_run_results\"\n",
    "os.makedirs(pytorch_2_multi_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Possible improvements/extensions\n",
    "\n",
    "* TK - use mixed precision training - https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples (more speedups)\n",
    "* Transformer based models may see better speedups than conv models (due to PyTorch 2.0) - https://pytorch.org/blog/pytorch-2.0-release/#stable-accelerated-pytorch-2-transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
