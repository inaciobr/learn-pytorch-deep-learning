{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: A Quick PyTorch 2.0 Tutorial\n",
    "\n",
    "In short:\n",
    "\n",
    "If you have a new GPU (NVIDIA 40XX or A100, A10G etc), you can \"compile\" your models and often see speed ups.\n",
    "\n",
    "**Before PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "### Train model ###\n",
    "\n",
    "### Test model ###\n",
    "```\n",
    "\n",
    "**After PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "compiled_model = torch.compile(model) # <- new!\n",
    "\n",
    "### Train model ### <- faster!\n",
    "\n",
    "### Test model ### <- faster!\n",
    "```\n",
    "\n",
    "Things to note:\n",
    "* TK - add where it doesn't work\n",
    "\n",
    "## TK - Resources to learn more\n",
    "* PyTorch 2.0 launch blog post - https://pytorch.org/get-started/pytorch-2.0/ \n",
    "* PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/ \n",
    "    * GitHub release notes - https://github.com/pytorch/pytorch/releases/tag/v2.0.0 (lots of info here!)\n",
    "* PyTorch default device context manager - https://github.com/pytorch/tutorials/pull/2220/files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# See here: https://github.com/pytorch/tutorials/pull/2220/files \n",
    "import torch\n",
    "with torch.device('cuda'):\n",
    "    mod = torch.nn.Linear(20, 30)\n",
    "    print(mod.weight.device)\n",
    "    print(mod(torch.randn(128, 20)).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0.dev20230313 (should be 2.x+)\n",
      "[INFO] PyTorch 2.0 installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch 2.0 (currently from nightlies)\n",
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 (currently from nightlies)\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* add in info about PyTorch 2.0\n",
    "* a quick upgrade for speed ups\n",
    "* a quick note on which GPU will be needed (works best on NVIDIA GPUs, not macOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Check GPU\n",
    "\n",
    "* Best speedups are on newer NVIDIA GPUs (this is because PyTorch 2.0 leverages new NVIDIA hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU information:\n",
      "Thu Mar 16 06:37:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   43C    P8    11W / 320W |    101MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       993      G   /usr/lib/xorg/Xorg                 86MiB |\n",
      "|    0   N/A  N/A      1202      G   /usr/bin/gnome-shell               10MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU name: NVIDIA GeForce RTX 4080\n",
      "GPU capability score: (8, 9)\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  print(f'GPU name: {gpu_name}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  gpu_score = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {gpu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TK - add a table for NVIDIA GPUs and architectures etc and which lead to speedups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Simple training example \n",
    "\n",
    "* CIFAR10\n",
    "* ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0.dev20230313\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision version: 0.15.0.dev20230313\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25557032\n"
     ]
    }
   ],
   "source": [
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "transforms = model_weights.transforms()\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.crop_size = 32\n",
    "transforms.resize_size = 32 # Resize to 32x32, CIFAR10 is 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=32\n",
       "    resize_size=32\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "* Generally GPUs aren't the bottleneck of ML code\n",
    "* Data loading is the main bottleneck\n",
    "    * E.g. you want to get your data to the GPU as fast as possible = more workers (though in my experience this generally caps at about ~4 workers per GPU, though don't trust me, better to do your own experiments)\n",
    "* You want your GPUs to go brrrrr - https://horace.io/brrr_intro.html \n",
    "    * More here on crazy matmul improvements - https://twitter.com/cHHillee/status/1630274804795445248?s=20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 391 batches of size 128\n",
      "Test dataloader length: 79 batches of size 128\n",
      "Using number of workers: 16 (generally more workers means faster dataloading from CPU to GPU)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "import os\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Using number of workers: {NUM_WORKERS} (generally more workers means faster dataloading from CPU to GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename to save the results\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_name = \"ResNet50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "def create_model():\n",
    "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "  # TK - adjust the output layer shape for CIFAR10\n",
    "  model.fc = torch.nn.Linear(2048, 10)\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70df0472578a4dbe84f74a6a937b92e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04299b56112346b8b3699982c50759bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee415f15b8a74848a19e5dcae2abbcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1024 | train_acc: 0.6368 | test_loss: 1.7512 | test_acc: 0.4925 | train_epoch_time: 10.5276 | test_epoch_time: 1.3578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0222c0766fa848a39d513bfa29a07c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911e833493147e2a88c4c240756ec74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 1.0224 | train_acc: 0.6616 | test_loss: 0.9931 | test_acc: 0.6658 | train_epoch_time: 8.3536 | test_epoch_time: 1.2717\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.11189961433410645 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ce94eb4d2d4387a3a92d3709770e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1d3edd872d4eeebed37518aa209f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/pytorch/env-nightly/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:93: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33c2637176b46789d8424f118ba856a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1955 | train_acc: 0.6053 | test_loss: 0.9915 | test_acc: 0.6735 | train_epoch_time: 34.9682 | test_epoch_time: 10.3872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0def919a66b449c5a90934c6cb869ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ad839e0e0d4312a90054f9216b8d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.8678 | train_acc: 0.7083 | test_loss: 1.2752 | test_acc: 0.5839 | train_epoch_time: 9.2625 | test_epoch_time: 1.2016\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "compile_start_time = time.time()\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "compile_results = train(model=compiled_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graphs of results and compiled_results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "compile_results_df = pd.DataFrame(compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.102421</td>\n",
       "      <td>0.636765</td>\n",
       "      <td>1.751239</td>\n",
       "      <td>0.492484</td>\n",
       "      <td>10.527614</td>\n",
       "      <td>1.357769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022397</td>\n",
       "      <td>0.661617</td>\n",
       "      <td>0.993084</td>\n",
       "      <td>0.665843</td>\n",
       "      <td>8.353620</td>\n",
       "      <td>1.271722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.102421   0.636765   1.751239  0.492484         10.527614   \n",
       "1    1.022397   0.661617   0.993084  0.665843          8.353620   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         1.357769  \n",
       "1         1.271722  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Make this more obvious that it's for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_train_epoch_time = results_df.train_epoch_time.mean()\n",
    "mean_test_epoch_time = results_df.test_epoch_time.mean()\n",
    "mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "mean_compile_train_epoch_time = compile_results_df.train_epoch_time.mean()\n",
    "mean_compile_test_epoch_time = compile_results_df.test_epoch_time.mean()\n",
    "mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "# Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "# Make both bars appear on the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "width = 0.3\n",
    "x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "# TK - make this title include dataset/model information for a better idea of what's happening\n",
    "plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) on {gpu_name} | {dataset_name} | {model_name}\")\n",
    "plt.legend();\n",
    "\n",
    "# mean_train_epoch_time, mean_compile_train_epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3147454261779785, 5.7943936586380005)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_epoch_time, mean_compile_test_epoch_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Save results to file with GPU details\n",
    "\n",
    "TODO:\n",
    "* Save the results to file with GPU name and other details (run on multiple machines)\n",
    "* Run for multiple passes (e.g. 5x runs to average the time over each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv',\n",
       " 'single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_non_compiled_results, save_name_for_compiled_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Try for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    return results\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# TK - the first time you compile a model, the first few epochs will be slower than subsequent runs\n",
    "# TK - consider the first few epochs of training to be a \"warmup\" period\n",
    "# def create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "#     model, transforms = create_model()\n",
    "#     model.to(device)\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                  lr=0.003)\n",
    "    \n",
    "#     compile_start_time = time.time()\n",
    "#     ### New in PyTorch 2.x ###\n",
    "#     compiled_model = torch.compile(model)\n",
    "#     ##########################\n",
    "#     compile_end_time = time.time()\n",
    "#     compile_time = compile_end_time - compile_start_time\n",
    "#     print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "#     compile_results = train(model=compiled_model,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             test_dataloader=test_dataloader,\n",
    "#                             loss_fn=loss_fn,\n",
    "#                             optimizer=optimizer,\n",
    "#                             epochs=NUM_EPOCHS,\n",
    "#                             device=device,\n",
    "#                             disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "#     return compile_results\n",
    "\n",
    "def create_compiled_model():\n",
    "    model, _ = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    compile_start_time = time.time()\n",
    "    ### New in PyTorch 2.x ###\n",
    "    compiled_model = torch.compile(model)\n",
    "    ##########################\n",
    "    compile_end_time = time.time()\n",
    "    compile_time = compile_end_time - compile_start_time\n",
    "    print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "    return compiled_model\n",
    "\n",
    "def train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
    "                                 lr=0.003)\n",
    "    \n",
    "    compile_results = train(model=model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=epochs,\n",
    "                            device=device,\n",
    "                            disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "    return compile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6daf090a07b4e68ba7fef717632583d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0233 | train_acc: 0.6613 | test_loss: 0.9620 | test_acc: 0.6944 | train_epoch_time: 8.3822 | test_epoch_time: 1.3666\n",
      "Epoch: 2 | train_loss: 0.6470 | train_acc: 0.7874 | test_loss: 0.6907 | test_acc: 0.7712 | train_epoch_time: 8.4705 | test_epoch_time: 1.4128\n",
      "Epoch: 3 | train_loss: 0.5098 | train_acc: 0.8303 | test_loss: 0.6589 | test_acc: 0.7859 | train_epoch_time: 8.5455 | test_epoch_time: 1.3712\n",
      "Epoch: 4 | train_loss: 0.4998 | train_acc: 0.8339 | test_loss: 0.6213 | test_acc: 0.7997 | train_epoch_time: 8.3854 | test_epoch_time: 1.3645\n",
      "Epoch: 5 | train_loss: 0.3691 | train_acc: 0.8776 | test_loss: 0.6080 | test_acc: 0.8015 | train_epoch_time: 8.3813 | test_epoch_time: 1.4081\n",
      "[INFO] Run 2 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.1189 | train_acc: 0.6290 | test_loss: 7.4376 | test_acc: 0.5281 | train_epoch_time: 8.3968 | test_epoch_time: 1.3925\n",
      "Epoch: 2 | train_loss: 1.0737 | train_acc: 0.6471 | test_loss: 1.1805 | test_acc: 0.6137 | train_epoch_time: 8.4698 | test_epoch_time: 1.3641\n",
      "Epoch: 3 | train_loss: 0.6889 | train_acc: 0.7669 | test_loss: 0.7035 | test_acc: 0.7670 | train_epoch_time: 8.3682 | test_epoch_time: 1.4723\n",
      "Epoch: 4 | train_loss: 0.5208 | train_acc: 0.8261 | test_loss: 0.6416 | test_acc: 0.7867 | train_epoch_time: 8.5417 | test_epoch_time: 1.4136\n",
      "Epoch: 5 | train_loss: 0.6868 | train_acc: 0.7737 | test_loss: 0.6648 | test_acc: 0.7775 | train_epoch_time: 8.6349 | test_epoch_time: 1.3766\n",
      "[INFO] Run 3 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.2237 | train_acc: 0.6013 | test_loss: 1.2839 | test_acc: 0.5806 | train_epoch_time: 8.4393 | test_epoch_time: 1.4141\n",
      "Epoch: 2 | train_loss: 0.8288 | train_acc: 0.7248 | test_loss: 1.5476 | test_acc: 0.6078 | train_epoch_time: 8.6058 | test_epoch_time: 1.3994\n",
      "Epoch: 3 | train_loss: 0.6426 | train_acc: 0.7834 | test_loss: 0.6193 | test_acc: 0.7900 | train_epoch_time: 8.3036 | test_epoch_time: 1.3337\n",
      "Epoch: 4 | train_loss: 0.4858 | train_acc: 0.8372 | test_loss: 0.6679 | test_acc: 0.7956 | train_epoch_time: 8.4354 | test_epoch_time: 1.3853\n",
      "Epoch: 5 | train_loss: 0.4175 | train_acc: 0.8591 | test_loss: 0.7624 | test_acc: 0.7596 | train_epoch_time: 8.1844 | test_epoch_time: 1.3877\n",
      "[INFO] Run 4 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0520 | train_acc: 0.6522 | test_loss: 3.2791 | test_acc: 0.5655 | train_epoch_time: 8.4700 | test_epoch_time: 1.4059\n",
      "Epoch: 2 | train_loss: 0.7564 | train_acc: 0.7487 | test_loss: 1.1870 | test_acc: 0.6668 | train_epoch_time: 8.3310 | test_epoch_time: 1.3757\n",
      "Epoch: 3 | train_loss: 1.2165 | train_acc: 0.6118 | test_loss: 1.0497 | test_acc: 0.6414 | train_epoch_time: 8.3605 | test_epoch_time: 1.3861\n",
      "Epoch: 4 | train_loss: 0.7732 | train_acc: 0.7404 | test_loss: 0.8830 | test_acc: 0.7079 | train_epoch_time: 8.3048 | test_epoch_time: 1.3980\n",
      "Epoch: 5 | train_loss: 0.5416 | train_acc: 0.8159 | test_loss: 0.6546 | test_acc: 0.7800 | train_epoch_time: 8.4331 | test_epoch_time: 1.3950\n",
      "[INFO] Run 5 of 5 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0413 | train_acc: 0.6536 | test_loss: 1.2014 | test_acc: 0.6151 | train_epoch_time: 8.6756 | test_epoch_time: 1.3942\n",
      "Epoch: 2 | train_loss: 0.9803 | train_acc: 0.6872 | test_loss: 3.6151 | test_acc: 0.3109 | train_epoch_time: 8.4764 | test_epoch_time: 1.3762\n",
      "Epoch: 3 | train_loss: 1.3800 | train_acc: 0.5357 | test_loss: 1.2836 | test_acc: 0.6176 | train_epoch_time: 8.4131 | test_epoch_time: 1.3971\n",
      "Epoch: 4 | train_loss: 0.9216 | train_acc: 0.6878 | test_loss: 1.1737 | test_acc: 0.6230 | train_epoch_time: 8.5751 | test_epoch_time: 1.3709\n",
      "Epoch: 5 | train_loss: 0.7167 | train_acc: 0.7576 | test_loss: 0.6618 | test_acc: 0.7709 | train_epoch_time: 8.5255 | test_epoch_time: 1.3931\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "NUM_RUNS = 5\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "non_compile_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.091867</td>\n",
       "      <td>0.639470</td>\n",
       "      <td>2.832797</td>\n",
       "      <td>0.596737</td>\n",
       "      <td>8.472784</td>\n",
       "      <td>1.394672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857212</td>\n",
       "      <td>0.719047</td>\n",
       "      <td>1.644164</td>\n",
       "      <td>0.594086</td>\n",
       "      <td>8.470718</td>\n",
       "      <td>1.385634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.887548</td>\n",
       "      <td>0.705594</td>\n",
       "      <td>0.862998</td>\n",
       "      <td>0.720372</td>\n",
       "      <td>8.398150</td>\n",
       "      <td>1.392065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640245</td>\n",
       "      <td>0.785117</td>\n",
       "      <td>0.797481</td>\n",
       "      <td>0.742583</td>\n",
       "      <td>8.448480</td>\n",
       "      <td>1.386481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.546334</td>\n",
       "      <td>0.816775</td>\n",
       "      <td>0.670329</td>\n",
       "      <td>0.777888</td>\n",
       "      <td>8.431838</td>\n",
       "      <td>1.392111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.091867   0.639470   2.832797  0.596737          8.472784   \n",
       "1    0.857212   0.719047   1.644164  0.594086          8.470718   \n",
       "2    0.887548   0.705594   0.862998  0.720372          8.398150   \n",
       "3    0.640245   0.785117   0.797481  0.742583          8.448480   \n",
       "4    0.546334   0.816775   0.670329  0.777888          8.431838   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         1.394672  \n",
       "1         1.385634  \n",
       "2         1.392065  \n",
       "3         1.386481  \n",
       "4         1.392111  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.0013861656188964844 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aee45ea3cb4ca394abf5040479aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 1.1913 | train_acc: 0.6179 | test_loss: 2.8806 | test_acc: 0.3488 | train_epoch_time: 32.6434 | test_epoch_time: 10.1572\n",
      "Epoch: 2 | train_loss: 1.0352 | train_acc: 0.6587 | test_loss: 0.8406 | test_acc: 0.7210 | train_epoch_time: 9.0170 | test_epoch_time: 1.3055\n",
      "Epoch: 3 | train_loss: 0.6275 | train_acc: 0.7891 | test_loss: 0.7265 | test_acc: 0.7495 | train_epoch_time: 8.9066 | test_epoch_time: 1.2959\n",
      "Epoch: 4 | train_loss: 0.5166 | train_acc: 0.8256 | test_loss: 0.6559 | test_acc: 0.7826 | train_epoch_time: 8.8731 | test_epoch_time: 1.2713\n",
      "Epoch: 5 | train_loss: 1.3533 | train_acc: 0.5850 | test_loss: 1.5189 | test_acc: 0.4485 | train_epoch_time: 8.9575 | test_epoch_time: 1.3303\n",
      "[INFO] Run 2 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 1.0826 | train_acc: 0.6209 | test_loss: 0.8356 | test_acc: 0.7140 | train_epoch_time: 8.7467 | test_epoch_time: 1.3110\n",
      "Epoch: 2 | train_loss: 0.6971 | train_acc: 0.7653 | test_loss: 0.8023 | test_acc: 0.7414 | train_epoch_time: 9.0799 | test_epoch_time: 1.2839\n",
      "Epoch: 3 | train_loss: 0.5200 | train_acc: 0.8274 | test_loss: 0.5818 | test_acc: 0.8060 | train_epoch_time: 9.1780 | test_epoch_time: 1.3027\n",
      "Epoch: 4 | train_loss: 0.4024 | train_acc: 0.8638 | test_loss: 0.6154 | test_acc: 0.7946 | train_epoch_time: 8.8748 | test_epoch_time: 1.2856\n",
      "Epoch: 5 | train_loss: 0.8131 | train_acc: 0.7538 | test_loss: 1.6604 | test_acc: 0.6703 | train_epoch_time: 9.0307 | test_epoch_time: 1.2653\n",
      "[INFO] Run 3 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.4857 | train_acc: 0.8367 | test_loss: 0.6491 | test_acc: 0.7925 | train_epoch_time: 9.1910 | test_epoch_time: 1.3035\n",
      "Epoch: 2 | train_loss: 0.3113 | train_acc: 0.8965 | test_loss: 0.7323 | test_acc: 0.7864 | train_epoch_time: 8.9658 | test_epoch_time: 1.3209\n",
      "Epoch: 3 | train_loss: 0.2352 | train_acc: 0.9224 | test_loss: 0.6889 | test_acc: 0.7945 | train_epoch_time: 9.5789 | test_epoch_time: 1.3038\n",
      "Epoch: 4 | train_loss: 0.1853 | train_acc: 0.9381 | test_loss: 0.6994 | test_acc: 0.7999 | train_epoch_time: 9.3885 | test_epoch_time: 1.3027\n",
      "Epoch: 5 | train_loss: 0.1450 | train_acc: 0.9514 | test_loss: 0.7091 | test_acc: 0.8116 | train_epoch_time: 9.1333 | test_epoch_time: 1.3278\n",
      "[INFO] Run 4 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.1374 | train_acc: 0.9547 | test_loss: 0.7540 | test_acc: 0.8093 | train_epoch_time: 9.1644 | test_epoch_time: 1.3234\n",
      "Epoch: 2 | train_loss: 0.1077 | train_acc: 0.9646 | test_loss: 0.7445 | test_acc: 0.8173 | train_epoch_time: 9.0176 | test_epoch_time: 1.3247\n",
      "Epoch: 3 | train_loss: 0.1391 | train_acc: 0.9557 | test_loss: 0.8373 | test_acc: 0.8041 | train_epoch_time: 8.8393 | test_epoch_time: 1.3652\n",
      "Epoch: 4 | train_loss: 0.0823 | train_acc: 0.9729 | test_loss: 0.7841 | test_acc: 0.8231 | train_epoch_time: 9.1433 | test_epoch_time: 1.3471\n",
      "Epoch: 5 | train_loss: 0.0629 | train_acc: 0.9793 | test_loss: 0.8597 | test_acc: 0.8114 | train_epoch_time: 9.1027 | test_epoch_time: 1.3386\n",
      "[INFO] Run 5 of 5 for compiled model\n",
      "Epoch: 1 | train_loss: 0.2772 | train_acc: 0.9303 | test_loss: 2.9415 | test_acc: 0.7707 | train_epoch_time: 9.1696 | test_epoch_time: 1.3553\n",
      "Epoch: 2 | train_loss: 0.1489 | train_acc: 0.9535 | test_loss: 0.8065 | test_acc: 0.8240 | train_epoch_time: 9.0549 | test_epoch_time: 1.3489\n",
      "Epoch: 3 | train_loss: 0.0285 | train_acc: 0.9905 | test_loss: 0.8927 | test_acc: 0.8238 | train_epoch_time: 9.0901 | test_epoch_time: 1.3217\n",
      "Epoch: 4 | train_loss: 0.0227 | train_acc: 0.9926 | test_loss: 1.0022 | test_acc: 0.8211 | train_epoch_time: 9.2563 | test_epoch_time: 1.3569\n",
      "Epoch: 5 | train_loss: 0.0270 | train_acc: 0.9913 | test_loss: 0.9819 | test_acc: 0.8208 | train_epoch_time: 9.0880 | test_epoch_time: 1.3521\n"
     ]
    }
   ],
   "source": [
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# Create compiled model\n",
    "compiled_model = create_compiled_model()\n",
    "\n",
    "compiled_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for compiled model\")\n",
    "    results = train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.634836</td>\n",
       "      <td>0.792098</td>\n",
       "      <td>1.612153</td>\n",
       "      <td>0.687065</td>\n",
       "      <td>13.783042</td>\n",
       "      <td>3.090060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460032</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.778026</td>\n",
       "      <td>9.027065</td>\n",
       "      <td>1.316792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.310062</td>\n",
       "      <td>0.897033</td>\n",
       "      <td>0.745460</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>9.118559</td>\n",
       "      <td>1.317852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.241863</td>\n",
       "      <td>0.918588</td>\n",
       "      <td>0.751415</td>\n",
       "      <td>0.804272</td>\n",
       "      <td>9.107222</td>\n",
       "      <td>1.312710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480252</td>\n",
       "      <td>0.852181</td>\n",
       "      <td>1.145992</td>\n",
       "      <td>0.712520</td>\n",
       "      <td>9.062433</td>\n",
       "      <td>1.322813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.634836   0.792098   1.612153  0.687065         13.783042   \n",
       "1    0.460032   0.847743   0.785241  0.778026          9.027065   \n",
       "2    0.310062   0.897033   0.745460  0.795570          9.118559   \n",
       "3    0.241863   0.918588   0.751415  0.804272          9.107222   \n",
       "4    0.480252   0.852181   1.145992  0.712520          9.062433   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         3.090060  \n",
       "1         1.316792  \n",
       "2         1.317852  \n",
       "3         1.312710  \n",
       "4         1.322813  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean()\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_epoch_times(non_compiled_results, compiled_results, multi_runs=False, num_runs=0, save=False, save_path=\"\"):\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "    # Make both bars appear on the same plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "    # TK - make this title include dataset/model information for a better idea of what's happening\n",
    "    if multi_runs:\n",
    "        plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) for {num_runs} runs | {gpu_name} | {dataset_name} | {model_name}\")\n",
    "    else:\n",
    "        plt.title(f\"Mean epoch time (on {NUM_EPOCHS} epochs) on {gpu_name} | {dataset_name} | {model_name}\")\n",
    "    plt.legend();\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean_epoch_times(non_compile_results_multiple_runs_df, compile_results_multiple_runs_df, multi_runs=True, num_runs=NUM_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_run_non_compiled_results_5_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n",
      "multi_run_compiled_results_5_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n"
     ]
    }
   ],
   "source": [
    "save_name_for_multi_run_non_compiled_results = f\"multi_run_non_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_multi_run_compiled_results = f\"multi_run_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "print(save_name_for_multi_run_non_compiled_results)\n",
    "print(save_name_for_multi_run_compiled_results)\n",
    "\n",
    "# Make a directory for multi_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_multi_run_results_dir = f\"{pytorch_2_results_dir}/multi_run_results\"\n",
    "os.makedirs(pytorch_2_multi_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Possible improvements/extensions\n",
    "\n",
    "* TK - use mixed precision training - https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples (more speedups)\n",
    "* Transformer based models may see better speedups than conv models (due to PyTorch 2.0) - https://pytorch.org/blog/pytorch-2.0-release/#stable-accelerated-pytorch-2-transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
